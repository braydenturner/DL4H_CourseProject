{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed3a4738-2e3b-4230-a760-5aa18887dbdd",
   "metadata": {},
   "source": [
    "# Deep Learning For Healthcare Course Project: INPREM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161bee9d-8169-434e-826e-2e4c9b29c687",
   "metadata": {},
   "source": [
    "https://www.kdd.org/kdd2020/accepted-papers/view/inprem-an-interpretable-and-trustworthy-predictive-model-for-healthcare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db47c1bd-157c-444a-be21-ebc3cdbd4645",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5063b31c-2e09-4c90-933d-34354f6fb5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: sparsemax in /opt/conda/lib/python3.8/site-packages (0.1.9)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from sparsemax) (1.11.0a0+bfe5ad2)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch->sparsemax) (4.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U sparsemax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f3dc9044-b4f4-4504-99a1-041a4d89e6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import ast\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from icd9 import ICD9\n",
    "\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sparsemax import Sparsemax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0dc863de-4dea-4fe9-b07c-f02da06a2872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 24\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "# define data path\n",
    "use_demo = True\n",
    "if use_demo:\n",
    "    DATA_PATH = \"demodata/\" # work with open source data\n",
    "else:\n",
    "    DATA_PATH = \"data/\" # work with PATIENT Data\n",
    "\n",
    "tree = ICD9('codes.json')\n",
    "# tree.find('001.1').parent.parent.code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b317c7b-cdec-477b-ab90-f5004336588c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADMISSIONS.csv\t   D_ICD_DIAGNOSES.csv\trtypes.pkl  types.pkl\r\n",
      "DIAGNOSES_ICD.csv  ICUSTAYS.csv\t\trtypes.txt  types.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls {DATA_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59820ba-ebce-486b-8c10-013ffb6615cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faafcd45-05f9-4855-89dc-c9f3afe2a3c9",
   "metadata": {},
   "source": [
    "For example, SUBJECT_ID refers to a unique patient, HADM_ID refers to a unique admission to the hospital, and ICUSTAY_ID refers to a unique admission to an intensive care unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78d39bac-2632-4d00-9982-d3d5c915774d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diag_icd (1761 lines):\n",
      "    hadm_id icd9_code\n",
      "0   142345     99591\n",
      "1   142345     99662\n",
      "2   142345      5672\n",
      "3   142345     40391\n",
      "4   142345     42731\n",
      "\n",
      "icustays (136 lines):\n",
      "    subject_id  hadm_id  icustay_id              outtime\n",
      "0       10006   142345      206504  2164-10-25 12:21:07\n",
      "1       10011   105331      232110  2126-08-28 18:59:00\n",
      "2       10013   165520      264446  2125-10-07 15:13:52\n",
      "3       10017   199207      204881  2149-05-31 22:19:17\n",
      "4       10019   177759      228977  2163-05-16 03:47:04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(filepath):\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "def convert_datetime_to_day(df):\n",
    "    temp = pd.DataFrame()\n",
    "    temp[\"date\"] = pd.to_datetime(df['outtime'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    return str(temp['date'].dt.year) + str(temp['date'].dt.month) + str(temp['date'].dt.day)\n",
    "\n",
    "diag_icd = load_dataset(os.path.join(DATA_PATH, 'DIAGNOSES_ICD.csv'))\n",
    "icd_descriptions = load_dataset(os.path.join(DATA_PATH, 'D_ICD_DIAGNOSES.csv'))\n",
    "icustays = load_dataset(os.path.join(DATA_PATH, 'ICUSTAYS.csv'))\n",
    "admissions = load_dataset(os.path.join(DATA_PATH, 'ADMISSIONS.csv'))\n",
    "\n",
    "diag_icd = diag_icd.rename(columns={\"hadm_id\".upper(): \"hadm_id\", \"icd9_code\".upper(): \"icd9_code\"})\n",
    "icustays = icustays.rename(columns={\"subject_id\".upper(): \"subject_id\", \"hadm_id\".upper(): \"hadm_id\", \"icustay_id\".upper(): \"icustay_id\", \"outtime\".upper(): \"outtime\"})\n",
    "\n",
    "diag_icd = diag_icd[[\"hadm_id\", \"icd9_code\"]]\n",
    "icustays = icustays[[\"subject_id\", \"hadm_id\", \"icustay_id\", \"outtime\"]]\n",
    "\n",
    "\n",
    "print(f\"diag_icd ({len(diag_icd)} lines):\\n\", diag_icd.head(), end=\"\\n\\n\")\n",
    "print(f\"icustays ({len(icustays)} lines):\\n\", icustays.head(), end=\"\\n\\n\")\n",
    "# print(f\"admissions ({admissions.size} lines):\\n\", admissions.head(), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b12ade38-be99-44c0-9fb7-e5c2dc2b1a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joined_df (1897 lines):\n",
      "   icd9_code  subject_id  icustay_id              outtime\n",
      "0     99591       10006      206504  2164-10-25 12:21:07\n",
      "1     99662       10006      206504  2164-10-25 12:21:07\n",
      "2      5672       10006      206504  2164-10-25 12:21:07\n",
      "3     40391       10006      206504  2164-10-25 12:21:07\n",
      "4     42731       10006      206504  2164-10-25 12:21:07\n"
     ]
    }
   ],
   "source": [
    "joined_df = pd.merge(diag_icd, icustays, how='inner', on='hadm_id')[[\"icd9_code\", \"subject_id\", \"icustay_id\", \"outtime\"]]\n",
    "print(f\"joined_df ({len(joined_df)} lines):\\n\", joined_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1f3438-5929-4f94-90fd-50e2af5b69b3",
   "metadata": {},
   "source": [
    "Convert y in to category labels. If (3, 4 ,5) always use left 3. If it starts with E, use (Exxx). If it starts with V, use (Vxx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6c847451-714f-4bd3-b80a-a37a497105c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 19 patients\n",
      "diag mapping for DIAG_707: 642\n",
      "reverse mapping for index 642: 707\n"
     ]
    }
   ],
   "source": [
    "def convert_codes(codes):\n",
    "    out = []\n",
    "    for code in codes:\n",
    "        code = str(code)\n",
    "        if code[0] == \"E\":\n",
    "            c = code[:4]\n",
    "        else:\n",
    "            c = code[:3]\n",
    "        out.append(c)\n",
    "        \n",
    "        unique_codes.add(c)\n",
    "       \n",
    "    return out\n",
    "\n",
    "def build_dictionaries():\n",
    "    \"\"\"Construct dicts to map/ reverse map string codes to keys, e.g. {'001': 0, '002': 1}\n",
    "    \n",
    "    Currently doesn't handle V correctly, heirarchy has a decimal place.\n",
    "    \"\"\"\n",
    "    categories = tree.find('001-139').siblings\n",
    "    category_codes = [category.code for category in categories] # 001-139, 140-239...\n",
    "    \n",
    "    subcategories = []\n",
    "    all_codes = []\n",
    "    \n",
    "    for category in category_codes:\n",
    "        nodes = (tree.find(category).children)\n",
    "        subcategories.append([node.code for node in nodes])\n",
    "    subcategories = [item for sublist in subcategories for item in sublist] # flatten list\n",
    "    for subcategory in subcategories:\n",
    "        nodes = (tree.find(subcategory).children)\n",
    "        all_codes.append([node.code for node in nodes])\n",
    "    all_codes = [item for sublist in all_codes for item in sublist] # flatten list\n",
    "    \n",
    "    types = dict((diag, idx) for idx, diag in enumerate(all_codes))\n",
    "    rtypes = dict((idx, diag) for idx, diag in enumerate(all_codes))\n",
    "    \n",
    "    return types, rtypes\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "unique_codes = set()\n",
    "types, rtypes = build_dictionaries()\n",
    "\n",
    "for name, patient in joined_df.sort_values(\"outtime\").groupby([\"subject_id\"]):\n",
    "    visits = []\n",
    "    for _, visit in patient.groupby([\"icustay_id\"]):\n",
    "        codes = visit[\"icd9_code\"].tolist()\n",
    "        codes = convert_codes(codes)\n",
    "        \n",
    "        visits.append(codes)\n",
    "    if len(visits) >= 2:\n",
    "        x, y_ = visits[:-1], visits[-1]\n",
    "        X.append(x)\n",
    "        y.append(y_)\n",
    "\n",
    "print(f\"Using {len(X)} patients\")\n",
    "\n",
    "# check mapping\n",
    "print('diag mapping for DIAG_707:', types['707'])\n",
    "print('reverse mapping for index 642:', rtypes[642])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "79702804-810c-41c6-9381-fb1681ac3cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(X) == len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "69f80811-2ae9-44bf-81bc-77b08f9edabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275 codes\n"
     ]
    }
   ],
   "source": [
    "# print(\"visits (x):\", X, \"\\n\")\n",
    "# print(\"last visit (y):\", y)\n",
    "\n",
    "print(len(unique_codes), \"codes\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0f406311-1f41-41f0-86dc-2d09a286533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICD 9 Codes for Binary Classification\n",
    "diabetes = (\"Diabetes\", \"250.xx\")\n",
    "heart_failure = (\"Heary Failure\", \"428.xx\")\n",
    "chronic_kidney_disease = (\"Chronic Kidney Disease\", \"585.xx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8da5af8",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b7071d",
   "metadata": {},
   "source": [
    "For each task, we randomly split each dataset into training, validation, and testing sets five times in a 75:10:15 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "1d8b0e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_size = 0.75\n",
    "\n",
    "X_train, X_remain, y_train, y_remain = train_test_split(X, y, train_size=0.75)\n",
    "\n",
    "test_size = 0.6 # (valid is 10% of remaining 25%, test is 15% of remaining 25%)\n",
    "\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_remain, y_remain, test_size=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bf4afc-5be4-4ac2-831a-60d6eaa52c10",
   "metadata": {},
   "source": [
    "## Build Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3895e91d-962b-40de-852d-afb900d64b6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return (self.x[index], self.y[index])\n",
    "        \n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "val_dataset = CustomDataset(X_valid, y_valid)\n",
    "test_dataset = CustomDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7f5e7e-a159-45df-a748-97b3c904c3fc",
   "metadata": {},
   "source": [
    "## Load the Data (DataLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f46fda0-2d1c-4529-a191-8f3f190e1b57",
   "metadata": {},
   "source": [
    "For each task, we randomly split each dataset into training, validation, and testing sets five times in a 75:10:15 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "784b31cb-ac66-46e2-80dd-b0d9813a973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        data: a list of samples fetched from `CustomDataset`\n",
    "        \n",
    "    Outputs:\n",
    "        x: a tensor of shape (# patients, max # visits, max # diagnosis codes) of type torch.long\n",
    "        masks: a tensor of shape (# patients, max # visits, max # diagnosis codes) of type torch.bool\n",
    "        rev_x: same as x but in reversed time. This will be used in our RNN model for masking \n",
    "        rev_masks: same as mask but in reversed time. This will be used in our RNN model for masking\n",
    "        y: a tensor of shape (# patients) of type torch.float\n",
    "        \n",
    "    Note that you can obtains the list of diagnosis codes and the list of hf labels\n",
    "        using: `sequences, labels = zip(*data)`\n",
    "    \"\"\"\n",
    "\n",
    "    sequences, labels = zip(*data)\n",
    "    print(\"seqs\", sequences, \"\\n\")\n",
    "    print(\"labels\", labels)\n",
    "    \n",
    "    num_patients = len(sequences)\n",
    "    num_visits = [len(patient) for patient in sequences]\n",
    "    num_codes = [len(visit) for patient in sequences for visit in patient]\n",
    "\n",
    "    max_num_visits = max(num_visits)\n",
    "    max_num_codes = max(num_codes)\n",
    "    \n",
    "    y = torch.zeros(len(labels), dtype=torch.float)\n",
    "    \n",
    "    # for label in labels:\n",
    "    #    # create one-hot vector\n",
    "    \n",
    "    x = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.long)\n",
    "    rev_x = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.long)\n",
    "    masks = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.bool)\n",
    "    rev_masks = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.bool)\n",
    "    for i_patient, patient in enumerate(sequences):\n",
    "        count = 0\n",
    "        for j_visit, visit in enumerate(patient):\n",
    "            \"\"\"\n",
    "            TODO: update `x`, `rev_x`, `masks`, and `rev_masks`\n",
    "            \"\"\"\n",
    "            visit_len = len(visit)\n",
    "            \n",
    "            for code in visit: # convert to mapping\n",
    "                code = types[code]\n",
    "            \n",
    "            x[i_patient][j_visit][:visit_len] = torch.tensor(types(visit), dtype=torch.long)\n",
    "            masks[i_patient][j_visit][:visit_len] = torch.ones((visit_len),dtype=torch.bool)\n",
    "            count += 1\n",
    "            \n",
    "        reverse_x = x[i_patient][:count]\n",
    "        reverse_mask = masks[i_patient][:count]\n",
    "        \n",
    "        rev_x[i_patient][:count] = torch.flip(reverse_x, [0])\n",
    "        rev_masks[i_patient][:count] = torch.flip(reverse_mask, [0])\n",
    "        \n",
    "    return x, masks, rev_x, rev_masks, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e8c87ac3-0929-4112-a412-ea39a870ccce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seqs ([['428', '486', '425', '276', '599', '428', '396', '397', '041', '427', '518', '250', '372', 'V10', 'V45', '533', 'V58', '443', '272', '401', '564', '365']], [['782', '162', '496', '285', '584', '518', '486']], [['276', '531', '719', '274', '272', 'V42', '585', '403', '453', '327', '197', '415', '197', '198', '150', '578', '486']], [['412', '427', '531', '401', '532']], [['584', '572', 'V49', '303', '537', '571', '276', '789', '276', '572', '261']], [['456', '401', '572', '070', '789', '287', '280', '584', '571']], [['V58', '305', 'V45', 'V43', '250', '458', '428', '276', '284', '295', '486', '428', '491', '518', '459', '276', '327', '401', 'E934', 'V58', '278', '790']], [['038', '584', '995', '427', '599', '416', '403', '428', '276', '518', '327', '486', 'V12', '278', '564', 'V54', '707', '250'], ['564', '278', 'V12', '327', '486', '250', '416', '707', '995', '599', 'V54', '038', '276', '427', '403', '428', '518', '584'], ['250', 'E885', '441', '733', '244', 'E878', '998', '585', '427', '285', '599', '403', '998', '584', '428', '428', '820']], [['443', '428', '196', '585', '486', '424', '518', '327', 'V58', '428', '274', '934', '285', '202', 'V10', '427', '276', '584']], [['707', '202', '707', '518', '482', '427', '200', '253', 'E930', '227', '564', '693', '275', '786', 'V12', 'V12', 'V87']], [['397', '227', '486', '584', '253', '428', '276', '707', '255', '294', '244', '250']], [['427', '789', '041', '595', '569', '619', '276', '584', '533', '456', '564', '287', 'E879', '553', '276', 'V88', '572', '571', '285', '070', 'V10', 'V15', '276', '518']], [['280', '599', '154', '789', '196', '715', '197', '584', '577', '782', '041', '197', '788', '596', '789', '401']], [['038', '785', '584', '038', '995', '401', '250', '357', '244'], ['707', '276', '276', '427', 'V58', '250', '357', '401', '995', '272', '285', '530', '244', 'V44', '438', '707', '038', '785', '584', '599', '311'], ['272', '995', 'V44', 'V12', 'V58', '285', '357', '530', '250', '427', '401', '707', '707', '788', '311', '276', '599', '584', '785', '038', '244'], ['V58', '311', 'V15', '272', '443', 'V44', 'V44', '038', '507', '707', '599', '344', '276', '995', '781', 'V44', '438', '707', '401', '244', '250', 'V58', '356', '427'], ['285', 'V44', '707', '250', '244', '427', '041', '112', '599', 'V44', '272', '357', '486', '707'], ['250', '038', '785', '486', '584', '276', '995', '357', '599', '707', '272', '438', 'V58', '285', 'V12', 'V44', '311', '427', '707', '244', '401', 'V58'], ['272', '518', '584', '578', '276', '530', '280', '250', '357', '401', '244', '427', '507'], ['599', '038', '995', '707', '707', '427', '276', 'V58', '357', '285', '244', '401', '438', 'V44', '250', '996'], ['995', '038', '785', '584', '276', '427', '599', '598'], ['311', '438', '272', '244', 'V44', '268', '443', '288', '357', '250', '599', '438', '536', '338', '995', '401', 'V49', '707', 'V13', '038', '507', '482', '344', '707', '584', '293', 'V44', '276', '427', '275', 'V15', 'V12', 'V58', 'V45', 'V12', '276', '707'], ['038', '785', '584', '599', '276', '995', 'V58', '438', '401', '427', '707', '707', '244', 'V44', '311', '357', '250'], ['584', '995', '401', '250', '530', '285', '707', '707', '507', '244', '038', '518'], ['038', '482', '507', '599', '536', '401', '357', '250', '995', '285', 'V58', '427', 'E879', '041', '707', '707', 'V44', '996', 'V12'], ['250', '401', '530', '707', '244', '357', '998', '038', '518', '584', '787', '995', '707', '008', '438']]) \n",
      "\n",
      "labels (['398', 'V58', '396', '397', '427', '799', '458', '401', '533', 'V58', '272', '443', 'V45', '365', 'V10', '486', '250', '560', 'V66'], ['162', '401', '496', '285', '276', '584', '486'], ['150', 'V58', '564', '280', '272', '453', '197', '403', 'V42', 'V12', '197', '198', '585', '530', '562', '276', '415'], ['575', 'V58', '401', '349', '518', '584', '577', '790', '575', '427', '276'], ['303', '537', '276', '585', '780', '599', 'V02', 'V15', '571', '452', '578', '799', '263', '456', '995', '486', '785', '518', '572', '584', '112', '276', '038'], ['456', '789', '571', '452', '070', '038', '995', '280', '518', '572', '584', '585', '785', '572'], ['428', '295', '424', '427', '278', '459', 'V43', 'V58', '276', '428', '287', '416', '250', '518', '327', '491', '707'], ['250', '518', '416', '327', '995', '278', '486', '038', '584', '599', '427', '403', '564', '428', '707', '276', 'V54', 'V12'], ['274', '327', '424', 'V10', '584', 'V58', '196', '443', '285', '428', '486', '518', '276', '934', '428', '427', '202', '585'], ['494', '351', '275', '453', '200', '604', '788', '603', '276', '370', '707', '227', '253', '518', '277', '584', '482', '707', '284', '483', '453', '512', '276', '518', '288', '357', 'V60', '715', '785', '528', '288', 'E933', '275', '564', 'E878', '458'], ['244', '995', '038', '276', '008', '428', '507', '250'], ['276', '572', '276', '564', '533', '427', '569', '041', '285', '456', 'V10', '571', 'E879', '518', '789', '287', '276', '553', '595', '619', '584', 'V15', 'V88', '070'], ['584', '599', '789', '196', '197', '577', '280', '782', '788', '789', '197', '154', '041', '715', '401', '596'], ['V49', '344', '519', '357', 'E879', '438', '438', '427', '536', '599', '250', '443', '401', '244', '311', '272', 'V58', 'V58'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'V10'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_995/3929076511.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrev_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrev_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_995/69517966.py\u001b[0m in \u001b[0;36mcollate_fn\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mvisit_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvisit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_patient\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj_visit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvisit_len\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'V10'"
     ]
    }
   ],
   "source": [
    "x, masks, rev_x, rev_masks, y = collate_fn(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c2d03a1e-7bd8-467c-b155-b1ab699ce8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def load_data(train_dataset, val_dataset, test_loader, collate_fn):\n",
    "    \n",
    "    batch_size = 32\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_loader, batch_size=batch_size, collate_fn=collate_fn)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "train_loader, val_loader, test_loader = load_data(train_dataset, val_dataset, test_dataset, collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c7b45-5f82-4852-8ad2-a7775c775d75",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ee0171-82a3-4f49-8baa-fef7e1f5efee",
   "metadata": {},
   "source": [
    "We treat the medical events taking place in EHR as medical codes, which are denoted as $c_{1}, c_{2},... c_{|C|}$ ∈ 𝐶, where |𝐶| is the total number of unique medical codes.\n",
    "\n",
    "One specific patient consist of a sequence of visits $v_{1}, v_{2},... v_{T}$ where we denote the number of visits in total as T.\n",
    "\n",
    "Each visit contains a subset of medical codes, and we denote each visit as a binary vector  $v_{t} ∈ \\{0, 1\\}_{|C|}$, where the 𝑖-th element is set to 1 if the 𝑡-th visit contains the medical code $c_{i}$, otherwise 0. The visits  $v_{1}, v_{2},... v_{T}$ are stacked to form an input matrix $X ∈ \\{0, 1\\}^{|C|xT}$ , which we use as the input for the network\n",
    "\n",
    "$E_{v} = {W}_{v}X$\n",
    "\n",
    "$E_{o} = {W}_{o}O$\n",
    "\n",
    "$E_{r} = \\alpha(\\beta \\odot (E_{v}+E_{o}))^{T}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b78ac0-1bc5-46fa-98ac-83ca4cd3695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaAttention(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.a_att = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        self.sparsemax = Sparsemax(dim=-1)\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, g):\n",
    "        \n",
    "        y = self.a_att(g)\n",
    "        sparse_max = self.sparsemax(y)\n",
    "        soft_max = self.softmax(y)\n",
    "        \n",
    "        out = (sparse_max + soft_max) / 2\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class BetaAttention(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim=256):\n",
    "        \n",
    "        self.b_att = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, h):\n",
    "        \n",
    "        y = self.b_att(h)\n",
    "        out = torch.tanh(y)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74799646-67a2-4780-a4e2-8eabedce15f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'types' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_455/825688894.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# load the model here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mINPREM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_codes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'types' is not defined"
     ]
    }
   ],
   "source": [
    "class INPREM(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_codes, embedding_dim=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_v = nn.Embedding(num_codes, embedding_dim)\n",
    "        self.embedding_o = nn.Embedding(num_codes, embedding_dim)\n",
    "        \n",
    "        self.att_a = AlphaAttention(embedding_dim)\n",
    "        \n",
    "        self.att_b = BetaAttention(embedding_dim)\n",
    "        \n",
    "        self.do = nn.Dropout(.5)\n",
    "    \n",
    "    def forward(self, X):\n",
    "    \n",
    "        # Pass through embedding\n",
    "        ev = self.embedding_v(X)\n",
    "        eo = self.embedding_o(o)\n",
    "        \n",
    "        er = self.att_a * (self.att_b @ (ev + eo)).T # double check this\n",
    "        \n",
    "        # Softmax\n",
    "        out = F.softmax(x)\n",
    "    \n",
    "\n",
    "# load the model here\n",
    "model = INPREM(num_codes = len(types))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe5e895-e644-4790-9a3e-51d2ffdfc451",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee84c93-6357-4d93-b612-b7fde9d30c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dataloader, device=None):\n",
    "    model.eval()\n",
    "    y_pred = torch.LongTensor()\n",
    "    y_score = torch.Tensor()\n",
    "    y_true = torch.LongTensor()\n",
    "    \n",
    "    for DATA in dataloader:\n",
    "        y_logit = model(DATA)\n",
    "\n",
    "        y_hat = (y_logit > 0.5).int()\n",
    "\n",
    "        y_score = torch.cat((y_score,  y_logit.detach().to('cpu')), dim=0)\n",
    "        y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n",
    "        y_true = torch.cat((y_true, y.detach().to('cpu')), dim=0)\n",
    "    \n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    roc_auc = roc_auc_score(y_true, y_score)\n",
    "    \n",
    "    return p, r, f, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e5aa54-d7b3-4983-a834-77c898657366",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e402cdc6-bb7b-4f0b-8efd-f6efff628b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, n_epochs):\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        train_loss = 0\n",
    "        for DATA, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x, masks, rev_x, rev_masks)\n",
    "\n",
    "            loss = criterion(y_hat, y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "        \n",
    "        p, r, f, roc_auc = eval(model, val_loader)\n",
    "        \n",
    "        print('Epoch: {} \\t Validation p: {:.2f}, r:{:.2f}, f: {:.2f}, roc_auc: {:.2f}'.format(epoch+1, p, r, f, roc_auc))\n",
    "        \n",
    "    return round(roc_auc, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630845b1-f35a-4f28-93d3-593bfa3e9993",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35875830-7833-4907-9b0e-721957ac0db9",
   "metadata": {},
   "source": [
    "For training all approaches, we use Adam with the batch size of 32 and the learning rate of 0.0005. The weight decay is set to 𝜆 = 0.0001 and the dropout rate is set to 0.5 for all approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ffaa109-7d45-4a3e-b9bb-0c9748a12770",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IMPREM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mIMPREM\u001b[49m(num_codes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(types))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# load the loss function\u001b[39;00m\n\u001b[1;32m      5\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'IMPREM' is not defined"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = IMPREM(num_codes = len(types))\n",
    "\n",
    "# load the loss function\n",
    "criterion = nn.BCELoss()\n",
    "# load the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "\n",
    "n_epochs = 5\n",
    "train(model, train_loader, val_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3b9314-e48e-41f1-bfec-a23381f59b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bbc121b-8d7d-4d90-84b8-eed2a485ace3",
   "metadata": {},
   "source": [
    "## Abblations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c088435-9f4e-47e4-9fd2-3743022347db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

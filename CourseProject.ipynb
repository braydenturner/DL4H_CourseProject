{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed3a4738-2e3b-4230-a760-5aa18887dbdd",
   "metadata": {},
   "source": [
    "# Deep Learning For Healthcare Course Project: INPREM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161bee9d-8169-434e-826e-2e4c9b29c687",
   "metadata": {},
   "source": [
    "https://www.kdd.org/kdd2020/accepted-papers/view/inprem-an-interpretable-and-trustworthy-predictive-model-for-healthcare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e2a581",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db47c1bd-157c-444a-be21-ebc3cdbd4645",
   "metadata": {},
   "source": [
    "## 1.1 Import Libraries\n",
    "\n",
    "We will need the [sparsemax](https://pypi.org/project/sparsemax/) library later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5063b31c-2e09-4c90-933d-34354f6fb5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.python.org/simple, https://pypi.apple.com/simple\n",
      "Requirement already satisfied: sparsemax in /opt/homebrew/lib/python3.9/site-packages (0.1.9)\n",
      "Requirement already satisfied: torch in /opt/homebrew/lib/python3.9/site-packages (from sparsemax) (1.10.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/homebrew/lib/python3.9/site-packages (from torch->sparsemax) (4.1.1)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.python.org/simple, https://pypi.apple.com/simple\n",
      "Collecting psutil\n",
      "  Downloading https://pypi.apple.com/packages/packages/47/b6/ea8a7728f096a597f0032564e8013b705aa992a0990becd773dcc4d7b4a7/psutil-5.9.0.tar.gz (478 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m478.3/478.3 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: psutil\n",
      "  Building wheel for psutil (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for psutil: filename=psutil-5.9.0-cp39-cp39-macosx_11_0_arm64.whl size=239572 sha256=3190326204ed154615f7473bc0e234b91a5eb22a006d3c3585d1e50476be2c0f\n",
      "  Stored in directory: /Users/braydenturner/Library/Caches/pip/wheels/06/de/de/5197b1e5e16ef4c5324c44e3315e578ae42a9537736ec97304\n",
      "Successfully built psutil\n",
      "Installing collected packages: psutil\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed psutil-5.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U sparsemax\n",
    "!pip3 install -U psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3dc9044-b4f4-4504-99a1-041a4d89e6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psutil\n",
    "import pickle\n",
    "import json\n",
    "import ast\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from icd9 import ICD9\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sparsemax import Sparsemax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dc863de-4dea-4fe9-b07c-f02da06a2872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no GPU found\n",
      "using patient data\n"
     ]
    }
   ],
   "source": [
    "# set seed\n",
    "seed = 24\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "# validate GPU usage\n",
    "print(\"using GPU\") if torch.cuda.is_available() else print(\"no GPU found\")\n",
    "\n",
    "# define data path\n",
    "use_demo = False\n",
    "if use_demo:\n",
    "    DATA_PATH = \"demodata/\" # work with open source data\n",
    "    print(\"using demo data\")\n",
    "else:\n",
    "    DATA_PATH = \"data/\" # work with certified patient data\n",
    "    print(\"using patient data\")\n",
    "\n",
    "# print metrics for each epoch (CPU, RAM, VRAM data) - will add time to each epoch\n",
    "print_metrics = False\n",
    "\n",
    "# icd9 tree structure\n",
    "tree = ICD9('codes.json')\n",
    "# tree.find('001.1').parent.parent.code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b317c7b-cdec-477b-ab90-f5004336588c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADMISSIONS.csv      DIAGNOSES_ICD.csv   D_ICD_DIAGNOSES.csv ICUSTAYS.csv\n"
     ]
    }
   ],
   "source": [
    "!ls {DATA_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59820ba-ebce-486b-8c10-013ffb6615cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.2 Import Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faafcd45-05f9-4855-89dc-c9f3afe2a3c9",
   "metadata": {},
   "source": [
    "First, we load the MIMIC-III dataset. We use 4 files from the dataset, `DIAGNOSES_ICD`, `D_ICD_DIAGNOSES`, `ICUSTAYS`, and `ADMISSIONS`. We initially format the data and drop the columns we don't need.\n",
    "\n",
    "For example, `subject_id` refers to a unique patient, `hadm_id` refers to a unique admission to the hospital, and `icustay_id` refers to a unique admission to an intensive care unit. We also keep the `out time` for each ICU stay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78d39bac-2632-4d00-9982-d3d5c915774d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diag_icd (651047 lines):\n",
      "    hadm_id icd9_code\n",
      "0   172335     40301\n",
      "1   172335       486\n",
      "2   172335     58281\n",
      "3   172335      5855\n",
      "4   172335      4254\n",
      "\n",
      "icustays (61532 lines):\n",
      "    subject_id  hadm_id  icustay_id              outtime\n",
      "0         268   110404      280836  2198-02-18 05:26:11\n",
      "1         269   106296      206613  2170-11-08 17:46:57\n",
      "2         270   188028      220345  2128-06-27 12:32:29\n",
      "3         271   173727      249196  2120-08-10 00:39:04\n",
      "4         272   164716      210407  2186-12-27 12:01:13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(filepath):\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "def convert_datetime_to_day(df):\n",
    "    temp = pd.DataFrame()\n",
    "    temp[\"date\"] = pd.to_datetime(df['outtime'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    return str(temp['date'].dt.year) + str(temp['date'].dt.month) + str(temp['date'].dt.day)\n",
    "\n",
    "diag_icd = load_dataset(os.path.join(DATA_PATH, 'DIAGNOSES_ICD.csv'))\n",
    "icd_descriptions = load_dataset(os.path.join(DATA_PATH, 'D_ICD_DIAGNOSES.csv'))\n",
    "icustays = load_dataset(os.path.join(DATA_PATH, 'ICUSTAYS.csv'))\n",
    "admissions = load_dataset(os.path.join(DATA_PATH, 'ADMISSIONS.csv'))\n",
    "\n",
    "diag_icd = diag_icd.rename(columns={\"hadm_id\".upper(): \"hadm_id\", \"icd9_code\".upper(): \"icd9_code\"})\n",
    "icustays = icustays.rename(columns={\"subject_id\".upper(): \"subject_id\", \"hadm_id\".upper(): \"hadm_id\", \"icustay_id\".upper(): \"icustay_id\", \"outtime\".upper(): \"outtime\"})\n",
    "\n",
    "diag_icd = diag_icd[[\"hadm_id\", \"icd9_code\"]]\n",
    "icustays = icustays[[\"subject_id\", \"hadm_id\", \"icustay_id\", \"outtime\"]]\n",
    "\n",
    "\n",
    "print(f\"diag_icd ({len(diag_icd)} lines):\\n\", diag_icd.head(), end=\"\\n\\n\")\n",
    "print(f\"icustays ({len(icustays)} lines):\\n\", icustays.head(), end=\"\\n\\n\")\n",
    "# print(f\"admissions ({admissions.size} lines):\\n\", admissions.head(), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31023aa1",
   "metadata": {},
   "source": [
    "We merge the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b12ade38-be99-44c0-9fb7-e5c2dc2b1a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joined_df (705921 lines):\n",
      "   icd9_code  subject_id  icustay_id              outtime\n",
      "0     40301         109      262652  2141-09-22 21:44:50\n",
      "1       486         109      262652  2141-09-22 21:44:50\n",
      "2     58281         109      262652  2141-09-22 21:44:50\n",
      "3      5855         109      262652  2141-09-22 21:44:50\n",
      "4      4254         109      262652  2141-09-22 21:44:50\n"
     ]
    }
   ],
   "source": [
    "joined_df = pd.merge(diag_icd, icustays, how='inner', on='hadm_id')[[\"icd9_code\", \"subject_id\", \"icustay_id\", \"outtime\"]]\n",
    "print(f\"joined_df ({len(joined_df)} lines):\\n\", joined_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1f3438-5929-4f94-90fd-50e2af5b69b3",
   "metadata": {},
   "source": [
    "Clean up ICD-9 codes and convert to category labels for `y`, append all of our converted codes to `X` and `y`, and finally build a dictionary to convert types to codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c847451-714f-4bd3-b80a-a37a497105c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8755 patients\n"
     ]
    }
   ],
   "source": [
    "def convert_codes(codes):\n",
    "    \"\"\"Clean up ICD-9 codes and convert to category labels for `y`.\n",
    "    \n",
    "    If the codes contain 3, 4, or 5 digits, always use left 3. \n",
    "    If it starts with E, use (Exxx). If it starts with V, use (Vxx).\n",
    "    Also appends to a unique set of data to check number of unique codes.\n",
    "    \n",
    "    Inputs:\n",
    "        codes: a set of ICD-9 codes\n",
    "    \n",
    "    Outputs:\n",
    "        out: an array of category codes\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for code in codes:\n",
    "        code = str(code)\n",
    "        if code[0] == \"E\":\n",
    "            c = code[:4]\n",
    "        else:\n",
    "            c = code[:3]\n",
    "        out.append(c)\n",
    "        \n",
    "        unique_codes.add(c)\n",
    "       \n",
    "    return out\n",
    "\n",
    "\n",
    "def build_dictionaries(codes):\n",
    "    \"\"\"Construct dicts to map/ reverse map string input codes to keys, e.g. {'001': 0, '002': 1}\n",
    "    \n",
    "    Inputs:\n",
    "        codes: a set of unique category codes\n",
    "    \n",
    "    Outputs:\n",
    "        types: a dictionary to map codes to types\n",
    "        rtypes: a dictionary to map types to codes\n",
    "    \"\"\"\n",
    "    types = dict((diag, idx) for idx, diag in enumerate(codes))\n",
    "    rtypes = dict((idx, diag) for idx, diag in enumerate(codes))\n",
    "    \n",
    "    return types, rtypes\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "all_codes = []\n",
    "unique_codes = set()\n",
    "\n",
    "# set up X and y\n",
    "for name, patient in joined_df.sort_values(\"outtime\").groupby([\"subject_id\"]):\n",
    "    visits = []\n",
    "    for _, visit in patient.groupby([\"icustay_id\"]):\n",
    "        codes = visit[\"icd9_code\"].tolist()\n",
    "        codes = convert_codes(codes)\n",
    "        visits.append(codes)\n",
    "    if len(visits) >= 2:\n",
    "        x, y_ = visits[:-1], visits[-1]\n",
    "        X.append(x)\n",
    "        y.append(y_)\n",
    "\n",
    "types, rtypes = build_dictionaries(list(unique_codes))\n",
    "print(f\"Using {len(X)} patients\")\n",
    "\n",
    "# check mapping\n",
    "# print(unique_codes)\n",
    "# print('diag mapping for DIAG_V10:', types['V10']) # 75\n",
    "# print('reverse mapping for index 75:', rtypes[75])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79702804-810c-41c6-9381-fb1681ac3cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(X) == len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69f80811-2ae9-44bf-81bc-77b08f9edabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1071 codes\n",
      "1071 types mappings\n"
     ]
    }
   ],
   "source": [
    "# print(\"visits (x):\", X, \"\\n\")\n",
    "# print(\"last visit (y):\", y)\n",
    "\n",
    "print(len(unique_codes), \"codes\") \n",
    "print(len(types), \"types mappings\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f406311-1f41-41f0-86dc-2d09a286533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICD 9 Codes for Binary Classification\n",
    "diabetes = (\"Diabetes\", \"250.xx\")\n",
    "heart_failure = (\"Heary Failure\", \"428.xx\")\n",
    "chronic_kidney_disease = (\"Chronic Kidney Disease\", \"585.xx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148ced3c",
   "metadata": {},
   "source": [
    "## 2. Build the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eee9b2",
   "metadata": {},
   "source": [
    "## 2.1 Build Custom Dataset\n",
    "\n",
    "We implement a custom dataset using PyTorch class `Dataset`, which will characterize the key features of the dataset we want to generate.\n",
    "\n",
    "We will use the sequences of diagnosis codes seqs up to the last visit as input and the diagnosis code of last visit as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db4bab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        '''Return the number of samples.\n",
    "        '''\n",
    "        \n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        '''Generates one sample of data.\n",
    "        '''\n",
    "        \n",
    "        return (self.x[index], self.y[index])\n",
    "        \n",
    "        \n",
    "# train_dataset = CustomDataset(X_train, y_train)\n",
    "# val_dataset = CustomDataset(X_valid, y_valid)\n",
    "# test_dataset = CustomDataset(X_test, y_test)\n",
    "dataset = CustomDataset(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f46fda0-2d1c-4529-a191-8f3f190e1b57",
   "metadata": {},
   "source": [
    "## 2.2 Collate Function\n",
    "\n",
    "This collate function `collate_fn()` will be called by `DataLoader` after fetching a list of samples using the indices from `CustomDataset` to collate the list of samples into batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "784b31cb-ac66-46e2-80dd-b0d9813a973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_retain(data):\n",
    "    \"\"\"\n",
    "    Collate the the list of samples into batches. For each patient, pad the diagnosis sequences \n",
    "    to the sample shape. The padding infomation is stored in `mask`.\n",
    "\n",
    "    Arguments:\n",
    "        data: a list of samples fetched from `CustomDataset`\n",
    "        \n",
    "    Outputs:\n",
    "        x: a tensor of shape (# patients, max # visits, max # diagnosis codes) of type torch.long\n",
    "        masks: a tensor of shape (# patients, max # visits, max # diagnosis codes) of type torch.bool\n",
    "        rev_x: same as x but in reversed time. This will be used in our RNN model for masking \n",
    "        rev_masks: same as mask but in reversed time. This will be used in our RNN model for masking\n",
    "        y: a tensor of shape (# patients) of type torch.float\n",
    "    \"\"\"\n",
    "\n",
    "    sequences, labels = zip(*data)\n",
    "    num_patients = len(sequences)\n",
    "    num_visits = [len(patient) for patient in sequences]\n",
    "    num_codes = [len(visit) for patient in sequences for visit in patient]\n",
    "\n",
    "    max_num_visits = max(num_visits)\n",
    "    max_num_codes = max(num_codes)\n",
    "    \n",
    "    y = torch.zeros((len(labels), len(types)), dtype=torch.bool)\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        # create one-hot vector\n",
    "        for l in label:\n",
    "            plc = types[l]\n",
    "            y[i][plc] = True\n",
    "    \n",
    "    x = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.long)\n",
    "    rev_x = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.long)\n",
    "    masks = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.bool)\n",
    "    rev_masks = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.bool)\n",
    "    for i_patient, patient in enumerate(sequences):\n",
    "        count = 0\n",
    "        for j_visit, visit in enumerate(patient):\n",
    "            \"\"\"\n",
    "            TODO: update `x`, `rev_x`, `masks`, and `rev_masks`\n",
    "            \"\"\"\n",
    "            visit_len = len(visit)\n",
    "            \n",
    "            typed_visit = visit.copy()\n",
    "            for idx, code in enumerate(visit): # convert to mapping\n",
    "                typed_visit[idx] = types[visit[idx]]\n",
    "            \n",
    "            x[i_patient][j_visit][:visit_len] = torch.tensor(typed_visit, dtype=torch.long)\n",
    "            masks[i_patient][j_visit][:visit_len] = torch.ones((visit_len),dtype=torch.bool)\n",
    "            count += 1\n",
    "            \n",
    "        reverse_x = x[i_patient][:count]\n",
    "        reverse_mask = masks[i_patient][:count]\n",
    "        \n",
    "        rev_x[i_patient][:count] = torch.flip(reverse_x, [0])\n",
    "        rev_masks[i_patient][:count] = torch.flip(reverse_mask, [0])\n",
    "        \n",
    "    return x, masks, rev_x, rev_masks, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c81276f8-6ccc-4e9b-bc7d-bc16d43dbe82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1071 40\n"
     ]
    }
   ],
   "source": [
    "num_visits = [len(patient) for patient in X]\n",
    "\n",
    "max_num_visits = max(num_visits)\n",
    "max_num_codes = len(types)\n",
    "\n",
    "def collate_fn_inprem(data):\n",
    "    \"\"\"\n",
    "    Collate the the list of samples into batches. For each patient, pad the diagnosis sequences \n",
    "    to the sample shape. \n",
    "        \n",
    "    Arguments:\n",
    "        data: a list of samples fetched from `CustomDataset`\n",
    "        \n",
    "    Outputs:\n",
    "        x: a tensor of shape (# patients, max # visits, max # diagnosis codes) of type torch.long\n",
    "        o:a tensor of shape (# patients, max # visits) of type torch.long\n",
    "        y: a tensor of shape (# patients) of type torch.float\n",
    "    \"\"\"\n",
    "\n",
    "    sequences, labels = zip(*data)\n",
    "    num_patients = len(sequences)\n",
    "\n",
    "    num_types = len(types)\n",
    "    max_num_codes = num_types\n",
    "    \n",
    "    y = torch.zeros((len(labels), num_types), dtype=torch.bool)\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        # create one-hot vector\n",
    "        for l in label:\n",
    "            plc = types[l]\n",
    "            y[i][plc] = True\n",
    "    \n",
    "    x = torch.zeros((num_patients, max_num_visits, num_types), dtype=torch.long)\n",
    "    o = torch.zeros((num_patients, max_num_visits), dtype=torch.long)\n",
    "    masks = torch.zeros((num_patients, max_num_visits, num_types), dtype=torch.bool)\n",
    "    for i_patient, patient in enumerate(sequences):\n",
    "        count = 1\n",
    "        for j_visit, visit in enumerate(patient):\n",
    "            for code in visit : # convert to mapping\n",
    "                plc = types[code]\n",
    "                x[i_patient][j_visit][plc] = True\n",
    "            o[i_patient][j_visit] = count\n",
    "            count += 1\n",
    "    \n",
    "    return x, o, y\n",
    "\n",
    "print(max_num_codes, max_num_visits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c31b6a5",
   "metadata": {},
   "source": [
    "## 2.3 Split Dataset\n",
    "\n",
    "For each task, we randomly split each dataset into training and validation sets in an 80:20 ratio. This differs from the paper's implementation which uses a 75:10:15 training, testing, and validation split five times. We ran into issues evaluating the model against a test set and chose to return back to the 80:20 training/ validation split we had learned in previous implementations like RETAIN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a20685d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 6566\n",
      "Length of val dataset: 2189\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "split = int(len(dataset)*0.75)\n",
    "\n",
    "lengths = [split, len(dataset) - split]\n",
    "train_dataset, val_dataset = random_split(dataset, lengths)\n",
    "\n",
    "print(\"Length of train dataset:\", len(train_dataset))\n",
    "print(\"Length of val dataset:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cf0295",
   "metadata": {},
   "source": [
    "## 2.4 Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2d03a1e-7bd8-467c-b155-b1ab699ce8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def load_data_retain(train_dataset, val_dataset, collate_fn):\n",
    "    \n",
    "    batch_size = 32\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "def load_data(train_dataset, val_dataset, collate_fn):\n",
    "    '''    \n",
    "    Return the data loader for  train and validation dataset\n",
    "    \n",
    "    Arguments:\n",
    "        train dataset: train dataset of type `CustomDataset`\n",
    "        val dataset: validation dataset of type `CustomDataset`\n",
    "        collate_fn: collate function\n",
    "        \n",
    "    Outputs:\n",
    "        train_loader, val_loader: train and validation dataloaders\n",
    "    '''\n",
    "    \n",
    "    batch_size = 32\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn_inprem, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn_inprem, shuffle=False)\n",
    "    # test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn_inprem, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "train_loader, val_loader= load_data(train_dataset, val_dataset, collate_fn_inprem)\n",
    "# train_loader, val_loader= load_data_retain(train_dataset, val_dataset, collate_fn_retain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c7b45-5f82-4852-8ad2-a7775c775d75",
   "metadata": {},
   "source": [
    "# 3. Build the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec381e0",
   "metadata": {},
   "source": [
    "We treat the medical events taking place in EHR as medical codes, which are denoted as  𝑐1,𝑐2,...𝑐|𝐶|  ∈ 𝐶, where |𝐶| is the total number of unique medical codes.\n",
    "\n",
    "One specific patient consist of a sequence of visits  𝑣1,𝑣2,...𝑣𝑇  where we denote the number of visits in total as T."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c92abe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Retain (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c76ecafd-fa54-4c90-b355-77e91339af85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_sum(alpha, beta, rev_v, rev_masks):\n",
    "    \"\"\"\n",
    "    TODO: mask select the hidden states for true visits (not padding visits) and then\n",
    "        sum the them up.\n",
    "\n",
    "    Arguments:\n",
    "        alpha: the alpha attention weights of shape (batch_size, seq_length, 1)\n",
    "        beta: the beta attention weights of shape (batch_size, seq_length, hidden_dim)\n",
    "        rev_v: the visit embeddings in reversed time of shape (batch_size, # visits, embedding_dim)\n",
    "        rev_masks: the padding masks in reversed time of shape (batch_size, # visits, # diagnosis codes)\n",
    "\n",
    "    Outputs:\n",
    "        c: the context vector of shape (batch_size, hidden_dim)\n",
    "        \n",
    "    NOTE: Do NOT use for loop.\n",
    "    \"\"\"\n",
    "    \n",
    "    out = None\n",
    "    \n",
    "    rev_masks = rev_masks.max(axis=2).values\n",
    "    rev_masks = rev_masks.unsqueeze(-1)\n",
    "    \n",
    "    v = rev_masks * rev_v\n",
    "    \n",
    "    out = torch.sum(alpha * beta * v, 1)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def sum_embeddings_with_mask(x, masks):\n",
    "    \"\"\"\n",
    "    Mask select the embeddings for true visits (not padding visits) and then sum the embeddings for each visit up.\n",
    "\n",
    "    Arguments:\n",
    "        x: the embeddings of diagnosis sequence of shape (batch_size, # visits, # diagnosis codes, embedding_dim)\n",
    "        masks: the padding masks of shape (batch_size, # visits, # diagnosis codes)\n",
    "\n",
    "    Outputs:\n",
    "        sum_embeddings: the sum of embeddings of shape (batch_size, # visits, embedding_dim)\n",
    "    \"\"\"\n",
    "    \n",
    "    x = x * masks.unsqueeze(-1)\n",
    "    x = torch.sum(x, dim = -2)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "eae07459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RETAIN(\n",
       "  (embedding_v): Embedding(1071, 256)\n",
       "  (embedding_o): Embedding(1071, 256)\n",
       "  (rnn_a): GRU(256, 256, batch_first=True)\n",
       "  (rnn_b): GRU(256, 256, batch_first=True)\n",
       "  (att_a): AlphaAttentionRetain(\n",
       "    (a_att): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (att_b): BetaAttentionRetain(\n",
       "    (b_att): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (do): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha attention\n",
    "# beta attention\n",
    "# attention sum\n",
    "# sum embeddings with mask\n",
    "\n",
    "class AlphaAttentionRetain(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Define the linear layer `self.a_att` for alpha-attention using `nn.Linear()`;\n",
    "        \n",
    "        Arguments:\n",
    "            hidden_dim: the hidden dimension\n",
    "        \"\"\"\n",
    "        \n",
    "        self.a_att = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, g):\n",
    "        \"\"\"\n",
    "        TODO: Implement the alpha attention.\n",
    "        \n",
    "        Arguments:\n",
    "            g: the output tensor from RNN-alpha of shape (batch_size, seq_length, hidden_dim) \n",
    "        \n",
    "        Outputs:\n",
    "            alpha: the corresponding attention weights of shape (batch_size, seq_length, 1)\n",
    "            \n",
    "        HINT: consider `torch.softmax`\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        y = self.a_att(g)\n",
    "        y = torch.softmax(y, 2)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "class BetaAttentionRetain(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Define the linear layer `self.b_att` for beta-attention using `nn.Linear()`;\n",
    "        \n",
    "        Arguments:\n",
    "            hidden_dim: the hidden dimension\n",
    "        \"\"\"\n",
    "        \n",
    "        self.b_att = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "\n",
    "    def forward(self, h):\n",
    "        \"\"\"\n",
    "        TODO: Implement the beta attention.\n",
    "        \n",
    "        Arguments:\n",
    "            h: the output tensor from RNN-beta of shape (batch_size, seq_length, hidden_dim) \n",
    "        \n",
    "        Outputs:\n",
    "            beta: the corresponding attention weights of shape (batch_size, seq_length, hidden_dim)\n",
    "            \n",
    "        HINT: consider `torch.tanh`\n",
    "        \"\"\"\n",
    "        \n",
    "        y = self.b_att(h)\n",
    "        y = torch.tanh(y)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "\n",
    "class RETAIN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_codes, embedding_dim=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_v = nn.Embedding(num_codes, embedding_dim)\n",
    "        self.embedding_o = nn.Embedding(num_codes, embedding_dim)\n",
    "        \n",
    "        self.rnn_a = nn.GRU(embedding_dim, embedding_dim, batch_first=True)\n",
    "        self.rnn_b = nn.GRU(embedding_dim, embedding_dim, batch_first=True)\n",
    "        \n",
    "        self.att_a = AlphaAttentionRetain(embedding_dim)\n",
    "        self.att_b = BetaAttentionRetain(embedding_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(embedding_dim, 1)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.do = nn.Dropout(.5)\n",
    "    \n",
    "    def forward(self, X, masks, rev_X, rev_masks):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            rev_x: the diagnosis sequence in reversed time of shape (# visits, batch_size, # diagnosis codes)\n",
    "            rev_masks: the padding masks in reversed time of shape (# visits, batch_size, # diagnosis codes)\n",
    "\n",
    "        Outputs:\n",
    "            out: probabilities of shape (batch_size)\n",
    "        \"\"\"\n",
    "    \n",
    "        rev_X = self.embedding_v(rev_X)\n",
    "        rev_X = self.embedding_o(rev_X)\n",
    "        \n",
    "        X_v = self.embedding_v(X)\n",
    "        X_o = self.embedding_o(X)\n",
    "        \n",
    "        g, _ = self.rnn_a(rev_x)\n",
    "        h, _ = self.rnn_b(rev_x)\n",
    "        \n",
    "        alpha = self.att_a(g)\n",
    "        beta = self.att_b(h)\n",
    "        \n",
    "        # c = attention_sum(alpha, beta, rev_x, rev_masks) # RETAIN\n",
    "        \n",
    "        logits = self.fc(c)\n",
    "        probs = self.sigmoid(logits)\n",
    "                      \n",
    "        out = F.softmax(probs.squeeze())\n",
    "    \n",
    "\n",
    "# load the model here\n",
    "retain = RETAIN(num_codes = len(types))\n",
    "retain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d182e1-2f5b-41db-b617-5ea9e376b302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_retain(model, train_loader, val_loader, n_epochs):\n",
    "    \"\"\"\n",
    "    Train the model.\n",
    "    \n",
    "    Arguments:\n",
    "        model: the RNN model\n",
    "        train_loader: training dataloder\n",
    "        val_loader: validation dataloader\n",
    "        n_epochs: total number of epochs\n",
    "    \"\"\"\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x, masks, rev_x, rev_masks, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x, masks, rev_x, rev_masks)\n",
    "            \"\"\" \n",
    "            TODO: calculate the loss using `criterion`, save the output to loss.\n",
    "            \"\"\"\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "        p, r, f, roc_auc = eval(model, val_loader)\n",
    "        print('Epoch: {} \\t Validation p: {:.2f}, r:{:.2f}, f: {:.2f}, roc_auc: {:.2f}'.format(epoch+1, p, r, f, roc_auc))\n",
    "    return round(roc_auc, 2)\n",
    "\n",
    "# load the model\n",
    "retain = RETAIN(num_codes = len(types))\n",
    "\n",
    "# load the loss function\n",
    "criterion = nn.BCELoss()\n",
    "# load the optimizer\n",
    "optimizer = torch.optim.Adam(retain.parameters(), lr=1e-3)\n",
    "\n",
    "n_epochs = 5\n",
    "train_retain(retain, train_loader, val_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ce4102",
   "metadata": {},
   "source": [
    "## INPREM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ee0171-82a3-4f49-8baa-fef7e1f5efee",
   "metadata": {},
   "source": [
    "Each visit contains a subset of medical codes, and we denote each visit as a binary vector  $v_{t} ∈ \\{0, 1\\}_{|C|}$, where the 𝑖-th element is set to 1 if the 𝑡-th visit contains the medical code $c_{i}$, otherwise 0. The visits  $v_{1}, v_{2},... v_{T}$ are stacked to form an input matrix $X ∈ \\{0, 1\\}^{|C|xT}$ , which we use as the input for the network\n",
    "\n",
    "$E_{v} = {W}_{v}X$\n",
    "\n",
    "$E_{o} = {W}_{o}O$\n",
    "\n",
    "$E_{r} = \\alpha(\\beta \\odot (E_{v}+E_{o}))^{T}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17b78ac0-1bc5-46fa-98ac-83ca4cd3695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaAttention(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lin = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        self.sparsemax = Sparsemax()\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, g):\n",
    "        \n",
    "        y = self.lin(g)\n",
    "        sparse_max = self.sparsemax(y)\n",
    "        soft_max = F.softmax(y, dim=1)\n",
    "        \n",
    "        out = (sparse_max + soft_max) / 2\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class BetaAttention(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lin = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, h):\n",
    "        \n",
    "        y = self.lin(h)\n",
    "        out = torch.tanh(y)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_codes, hidden_dim=256, num_attention_layers=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc_q = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_v = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_k = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.fc_multi = nn.Linear(num_attention_layers * hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv1d(hidden_dim, hidden_dim, 1)\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv1d(hidden_dim, hidden_dim, 1)\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, E):\n",
    "        \n",
    "        Q = self.fc_q(E)\n",
    "        K = self.fc_k(E)\n",
    "        V = self.fc_v(E)\n",
    "        \n",
    "        attn = V * F.softmax((Q * K) / math.sqrt(self.hidden_dim), dim=1)\n",
    "        \n",
    "        x = self.fc_multi(torch.concat((attn, attn), dim=2))\n",
    "        \n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "74799646-67a2-4780-a4e2-8eabedce15f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INPREM(\n",
       "  (embedding_v): Linear(in_features=1071, out_features=256, bias=False)\n",
       "  (embedding_o): Linear(in_features=1, out_features=256, bias=False)\n",
       "  (att_a): AlphaAttention(\n",
       "    (lin): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (sparsemax): Sparsemax(dim=-1)\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       "  (att_b): BetaAttention(\n",
       "    (lin): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (multi_attn): MultiHeadAttention(\n",
       "    (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (fc_multi): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (conv1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (fc): Linear(in_features=256, out_features=1071, bias=True)\n",
       "  (do): Dropout(p=0.5, inplace=False)\n",
       "  (tan): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class INPREM(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_codes, num_visits, embedding_dim=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # self.embedding_v = nn.Embedding(num_codes, embedding_dim)\n",
    "        # self.embedding_o = nn.Embedding(num_codes, embedding_dim)\n",
    "        \n",
    "        self.embedding_v = nn.Linear(num_codes, embedding_dim, bias=False)\n",
    "        self.embedding_o = nn.Linear(1, embedding_dim, bias=False)\n",
    "        \n",
    "        self.att_a = AlphaAttention(embedding_dim)\n",
    "        self.att_b = BetaAttention(embedding_dim)\n",
    "        \n",
    "        self.multi_attn = MultiHeadAttention(num_codes, embedding_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(embedding_dim, num_codes)\n",
    "        \n",
    "        self.do = nn.Dropout(.5)\n",
    "        \n",
    "        self.tan = nn.Tanh()\n",
    "    \n",
    "    def forward(self, X, O):\n",
    "        \"\"\"\n",
    "        Implement the INPREM Model\n",
    "        \"\"\"\n",
    "        \n",
    "        X = X.type(torch.FloatTensor)\n",
    "        O = O.type(torch.FloatTensor)\n",
    "        \n",
    "        O = O.unsqueeze(dim=2)\n",
    "        \n",
    "        E_o = O.unsqueeze(dim=1)\n",
    "        \n",
    "        # Get E_v\n",
    "        E_v = self.embedding_v(X)\n",
    "        E_o = self.embedding_o(O)\n",
    "        \n",
    "        E = torch.add(E_o,E_v)\n",
    "        \n",
    "        H =  self.multi_attn(E)\n",
    "        H =  self.multi_attn(H)\n",
    "        \n",
    "        beta = self.att_b(H)\n",
    "        alpha = self.att_a(H).permute(0,2,1)\n",
    "        \n",
    "        E_r = (alpha @ (beta * E))\n",
    "        \n",
    "        out = self.fc(E_r)\n",
    "        \n",
    "        out = out.squeeze()\n",
    "        out = F.softmax(out)\n",
    "        # out = self.tan(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "# load the model here\n",
    "model = INPREM(len(types), max_num_visits)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe5e895-e644-4790-9a3e-51d2ffdfc451",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Training and Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f978aa09",
   "metadata": {},
   "source": [
    "## 4.1 Define Evaluation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1ee84c93-6357-4d93-b612-b7fde9d30c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "\n",
    "def eval(model, val_loader):\n",
    "    \n",
    "    \"\"\"\n",
    "    Evaluate the model.\n",
    "    \n",
    "    Arguments:\n",
    "        model: the RNN model\n",
    "        val_loader: validation dataloader\n",
    "        \n",
    "    Outputs:\n",
    "        precision: overall precision score\n",
    "        recall: overall recall score\n",
    "        f1: overall f1 score\n",
    "        roc_auc: overall roc_auc score\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    y_pred = torch.LongTensor()\n",
    "    y_score = torch.Tensor()\n",
    "    y_true = torch.LongTensor()\n",
    "    model.eval()\n",
    "    for x, o, y in val_loader:\n",
    "        y_logit = model(x, o)\n",
    "        \"\"\"\n",
    "        TODO: obtain the predicted class (0, 1) by comparing y_logit against 0.5, \n",
    "              assign the predicted class to y_hat.\n",
    "        \"\"\"\n",
    "        y_hat = (y_logit > 0.5).int()\n",
    "\n",
    "        y_score = torch.cat((y_score,  y_logit.detach().to('cpu')), dim=0)\n",
    "        y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n",
    "        y_true = torch.cat((y_true, y.detach().to('cpu')), dim=0)\n",
    "    \n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true, y_pred)\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_true, y_score)\n",
    "    \n",
    "    return p, r, f, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e5aa54-d7b3-4983-a834-77c898657366",
   "metadata": {},
   "source": [
    "## 4.2 Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e402cdc6-bb7b-4f0b-8efd-f6efff628b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, n_epochs):\n",
    "    \"\"\"\n",
    "    Train the model.\n",
    "    \n",
    "    Arguments:\n",
    "        model: the RNN model\n",
    "        train_loader: training dataloder\n",
    "        val_loader: validation dataloader\n",
    "        n_epochs: total number of epochs\n",
    "    \n",
    "    Outputs: \n",
    "        roc_auc (rounded, 2): the ROC AUC score for the predictions\n",
    "    \"\"\"\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        train_loss = 0\n",
    "        for x, o, y in train_loader:\n",
    "        # for DATA, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            y_hat = model(x, o)\n",
    "            torch.set_printoptions(threshold=6)\n",
    "            \n",
    "            y = y.type(torch.FloatTensor)\n",
    "            \n",
    "            print(y_hat.max(axis=0))\n",
    "\n",
    "            loss = criterion(y_hat, y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "        \n",
    "        p, r, f, roc_auc = eval(model, val_loader)\n",
    "        \n",
    "        print('Epoch: {} \\t Validation p: {:.2f}, r:{:.2f}, f: {:.2f}, roc_auc: {:.2f}'.format(epoch+1, p, r, f, roc_auc))\n",
    "        \n",
    "        # get performance data\n",
    "        if print_metrics:\n",
    "            print('The CPU usage over the last 5 seconds is: {}'.format(psutil.cpu_percent(5)))\n",
    "            print('RAM used is: {} GB'.format(psutil.virtual_memory()[3]/1000000000))\n",
    "            print('GPU memory (VRAM) used: {} GB'.format((torch.cuda.mem_get_info()[1] - torch.cuda.mem_get_info()[0])/1000000000))\n",
    "        \n",
    "    return round(roc_auc, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630845b1-f35a-4f28-93d3-593bfa3e9993",
   "metadata": {},
   "source": [
    "### Run Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35875830-7833-4907-9b0e-721957ac0db9",
   "metadata": {},
   "source": [
    "For training all approaches, we use Adam with the batch size of 32 and the learning rate of 0.0005. The weight decay is set to 𝜆 = 0.0001 and the dropout rate is set to 0.5 for all approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3ffaa109-7d45-4a3e-b9bb-0c9748a12770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jc/85vy06cn6b13gcm4rcvz9_fw0000gq/T/ipykernel_35571/1626535246.py:54: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = F.softmax(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([0.0010, 0.0010, 0.0009,  ..., 0.0009, 0.0009, 0.0010],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 6, 20, 11,  ...,  0, 19, 16]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0010, 0.0010, 0.0009,  ..., 0.0009, 0.0009, 0.0010],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 9, 26, 23,  ..., 16, 21,  9]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0015, 0.0010, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([26,  0, 14,  ..., 15, 16, 10]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0010, 0.0010, 0.0009,  ..., 0.0009, 0.0009, 0.0010],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 4,  2, 12,  ...,  3, 24,  4]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0010, 0.0010, 0.0009,  ..., 0.0009, 0.0009, 0.0010],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([27,  5,  1,  ..., 23, 11, 27]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0010, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 0,  0, 12,  ...,  6,  2,  0]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0010, 0.0010, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([15, 15, 29,  ..., 20,  0, 24]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0010, 0.0010, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([13, 13, 24,  ..., 26,  0, 13]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0010, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([11, 11, 24,  ..., 30,  2, 10]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0010, 0.0010, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([20, 20, 15,  ...,  9,  9, 13]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0010, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 1,  1, 18,  ..., 28, 29,  1]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0011, 0.0011, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([29, 29,  8,  ...,  3, 31, 16]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0010, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([18, 18,  4,  ...,  9,  9, 29]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0010, 0.0011, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([17, 17,  8,  ..., 31, 31, 26]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0010, 0.0011, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 7, 28, 23,  ..., 31, 10, 29]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0010, 0.0012, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([14, 14,  0,  ..., 22, 22, 16]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0010, 0.0012, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([24, 24,  1,  ..., 17, 22, 11]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0010, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([12, 11,  4,  ..., 14, 20, 19]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0010, 0.0013, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([23, 23, 29,  ..., 28,  3,  2]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0013, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([11, 28, 10,  ..., 10,  4, 21]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0011, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([16, 16,  2,  ...,  2,  2,  3]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0011, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 1,  1, 31,  ..., 20,  2, 20]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0012, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([15,  5, 21,  ..., 21, 19,  0]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0012, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([22, 31, 12,  ..., 18, 28, 17]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0010, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([10, 24, 19,  ..., 20,  5,  6]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0011, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 5, 16, 29,  ..., 23, 14, 20]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0012, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([25, 20, 11,  ..., 22, 26,  6]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0011, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 6,  4, 14,  ...,  8, 25, 12]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0011, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 5, 13, 28,  ..., 24, 17, 24]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0012, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([16,  7,  5,  ..., 13, 22,  4]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0012, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([13, 23,  0,  ..., 10, 26, 26]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0011, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([27, 19, 15,  ..., 16, 20, 18]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0010, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([18, 25, 10,  ..., 30, 12, 15]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0011, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 6, 12, 10,  ...,  5,  4, 19]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0011, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([28, 13, 19,  ..., 28, 16,  2]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0011, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([17, 15, 12,  ..., 26, 22, 21]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0010, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 1, 21,  7,  ..., 20,  8,  5]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0011, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([13, 18, 26,  ..., 22, 23, 17]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0011, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 2,  8, 25,  ...,  6,  6, 16]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0011, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([17, 20, 24,  ..., 12,  0, 12]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0011, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([18, 19, 13,  ..., 16,  8, 16]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0011, 0.0010,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([27, 26, 26,  ..., 22, 27, 19]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0010, 0.0010,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([12,  4,  4,  ..., 18, 18,  5]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0011, 0.0010,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 5,  3, 19,  ...,  9,  9,  9]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0011, 0.0010,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 7, 12,  6,  ...,  4,  4,  7]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0010, 0.0010,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([14,  4, 30,  ..., 14, 14, 22]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0010, 0.0010,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([21, 28, 27,  ..., 13, 19, 13]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0010, 0.0010,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([26,  8, 23,  ..., 26, 26, 26]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0010, 0.0010,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([16, 28, 28,  ..., 16, 16, 16]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0009, 0.0010, 0.0010,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([11, 19, 18,  ..., 11, 11, 11]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0008, 0.0010, 0.0010,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 5, 28, 15,  ..., 24,  5, 24]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0008, 0.0010, 0.0011,  ..., 0.0009, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 5, 17,  8,  ...,  5,  5,  5]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0008, 0.0010, 0.0011,  ..., 0.0008, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([13,  7, 15,  ..., 13, 13, 13]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0008, 0.0010, 0.0011,  ..., 0.0008, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([15,  4, 23,  ..., 15, 15, 18]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0008, 0.0010, 0.0010,  ..., 0.0008, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([15, 25,  5,  ..., 15, 25, 25]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0008, 0.0010, 0.0011,  ..., 0.0008, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([25, 18, 28,  ..., 25, 25, 25]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0008, 0.0010, 0.0011,  ..., 0.0008, 0.0009, 0.0009],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([29, 21,  5,  ..., 29, 29, 29]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0008, 0.0009, 0.0011,  ..., 0.0008, 0.0009, 0.0008],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([22, 22, 29,  ..., 18, 18, 22]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0008, 0.0009, 0.0011,  ..., 0.0008, 0.0009, 0.0008],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([28, 28, 12,  ..., 28, 28, 28]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0008, 0.0009, 0.0011,  ..., 0.0008, 0.0009, 0.0008],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 0,  6, 16,  ...,  0, 21,  0]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0008, 0.0009, 0.0012,  ..., 0.0008, 0.0009, 0.0008],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([23, 23, 16,  ..., 23, 23, 23]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0008, 0.0009, 0.0012,  ..., 0.0008, 0.0009, 0.0008],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([31, 31, 24,  ..., 31, 31, 31]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0012,  ..., 0.0007, 0.0009, 0.0008],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([11, 11, 23,  ..., 11, 11, 11]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0012,  ..., 0.0007, 0.0009, 0.0008],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([26, 26,  5,  ..., 26, 26, 26]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0012,  ..., 0.0007, 0.0009, 0.0008],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 9,  9, 15,  ...,  9,  9,  9]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0012,  ..., 0.0007, 0.0009, 0.0008],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([20, 20, 23,  ..., 20, 20, 20]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0012,  ..., 0.0007, 0.0009, 0.0008],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([18, 18,  1,  ..., 18, 18, 18]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0012,  ..., 0.0007, 0.0008, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([16, 16, 17,  ..., 16, 16, 16]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0013,  ..., 0.0007, 0.0008, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([27, 27, 30,  ..., 27, 27, 27]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0013,  ..., 0.0007, 0.0008, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([15, 15, 29,  ..., 15, 15, 15]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0008, 0.0013,  ..., 0.0007, 0.0008, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([28, 28, 23,  ..., 28, 28, 28]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0008, 0.0013,  ..., 0.0007, 0.0008, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 5,  5, 31,  ...,  5,  5,  5]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0008, 0.0013,  ..., 0.0007, 0.0008, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([31, 31, 18,  ..., 31, 31, 31]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0008, 0.0013,  ..., 0.0007, 0.0008, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([18, 18, 10,  ..., 18, 21, 18]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0008, 0.0013,  ..., 0.0007, 0.0008, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([17, 17, 19,  ..., 17, 17, 17]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0008, 0.0013,  ..., 0.0007, 0.0008, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([25, 25, 21,  ..., 25, 25, 25]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0008, 0.0014,  ..., 0.0007, 0.0008, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([14, 14, 21,  ..., 14, 14, 14]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0008, 0.0013,  ..., 0.0007, 0.0008, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([30, 30, 18,  ..., 30, 30, 30]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0008, 0.0014,  ..., 0.0007, 0.0008, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([7, 7, 2,  ..., 7, 7, 7]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0008, 0.0014,  ..., 0.0007, 0.0008, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([17, 17, 30,  ..., 17, 17, 17]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0008, 0.0014,  ..., 0.0007, 0.0008, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([16, 16, 30,  ..., 16, 16, 16]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0008, 0.0014,  ..., 0.0007, 0.0008, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([12, 12, 23,  ..., 12, 12, 12]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0007, 0.0014,  ..., 0.0007, 0.0008, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([22, 22,  6,  ..., 22, 22, 22]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0007, 0.0013,  ..., 0.0007, 0.0008, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([15, 15, 13,  ..., 15, 15, 15]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0007, 0.0013,  ..., 0.0008, 0.0008, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([28, 28, 15,  ..., 28, 28, 28]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0007, 0.0013,  ..., 0.0008, 0.0008, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([13, 13, 28,  ..., 13, 13, 13]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0007, 0.0013,  ..., 0.0008, 0.0008, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([14, 14, 30,  ..., 14, 14, 14]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0007, 0.0013,  ..., 0.0008, 0.0008, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([30, 30, 11,  ..., 30, 30, 30]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0007, 0.0013,  ..., 0.0008, 0.0008, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([30, 30, 28,  ..., 30, 30, 30]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0007, 0.0013,  ..., 0.0008, 0.0008, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([14, 14, 18,  ..., 14, 14, 14]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0007, 0.0013,  ..., 0.0008, 0.0008, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([6, 6, 5,  ..., 6, 6, 6]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0007, 0.0013,  ..., 0.0008, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([10, 10,  3,  ..., 10, 10, 10]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0008, 0.0013,  ..., 0.0008, 0.0008, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([27, 27,  1,  ..., 27, 27, 27]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0008, 0.0013,  ..., 0.0008, 0.0008, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 7,  ..., 1, 1, 1]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0008, 0.0013,  ..., 0.0008, 0.0007, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([26, 26, 16,  ..., 26, 26, 26]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0008, 0.0013,  ..., 0.0008, 0.0007, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 8,  8, 10,  ...,  8,  8,  8]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0008, 0.0012,  ..., 0.0008, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([13, 13, 12,  ..., 13, 13, 13]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0012,  ..., 0.0008, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([24, 24,  6,  ..., 24, 24, 24]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0008, 0.0012,  ..., 0.0008, 0.0007, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([10, 10, 24,  ..., 10, 10, 10]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0008, 0.0012,  ..., 0.0008, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([26, 26, 10,  ..., 26, 26, 26]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0008, 0.0012,  ..., 0.0008, 0.0007, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 9,  9, 22,  ...,  9,  9,  9]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0012,  ..., 0.0008, 0.0007, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([24, 24,  7,  ..., 24, 24, 24]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0013,  ..., 0.0008, 0.0007, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 0,  0, 29,  ...,  0,  0,  0]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0013,  ..., 0.0008, 0.0007, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([10, 10, 17,  ..., 10, 10, 10]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0013,  ..., 0.0008, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 6,  6, 27,  ...,  6,  6,  6]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0014,  ..., 0.0008, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([11, 11, 24,  ..., 11, 11, 11]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0014,  ..., 0.0008, 0.0007, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 8, 11,  1,  ...,  8,  8,  8]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0014,  ..., 0.0008, 0.0007, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([9, 9, 8,  ..., 9, 9, 9]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0014,  ..., 0.0008, 0.0007, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([29, 29,  3,  ..., 29, 29, 29]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0014,  ..., 0.0008, 0.0007, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([25, 25, 18,  ..., 25, 25, 25]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0014,  ..., 0.0008, 0.0007, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([21, 21,  5,  ..., 21, 21, 21]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0014,  ..., 0.0008, 0.0007, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([19, 19, 10,  ..., 19, 19, 19]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0010, 0.0014,  ..., 0.0008, 0.0007, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([17,  4,  2,  ..., 17, 17, 17]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0014,  ..., 0.0008, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([12, 13, 10,  ..., 12, 12, 12]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0010, 0.0015,  ..., 0.0008, 0.0007, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 6, 11,  2,  ...,  6,  6,  6]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0010, 0.0015,  ..., 0.0008, 0.0007, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 7, 20,  1,  ...,  7,  7,  7]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0015,  ..., 0.0008, 0.0007, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([31, 31,  6,  ..., 31, 31, 31]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0010, 0.0015,  ..., 0.0008, 0.0007, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([16, 16,  4,  ..., 16, 16, 16]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0015,  ..., 0.0008, 0.0007, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([11, 11, 29,  ..., 11, 11, 11]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0015,  ..., 0.0008, 0.0007, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([25, 25, 24,  ..., 25, 25, 25]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0016,  ..., 0.0007, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([16, 16,  0,  ..., 16, 16, 16]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0010, 0.0016,  ..., 0.0008, 0.0007, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([25, 25, 29,  ..., 25, 25, 25]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0010, 0.0017,  ..., 0.0008, 0.0007, 0.0007],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([31, 31, 22,  ..., 31, 31, 31]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0017,  ..., 0.0008, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([11, 11, 29,  ..., 11, 11, 11]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0018,  ..., 0.0008, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 0,  0, 24,  ...,  0,  0,  0]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0019,  ..., 0.0007, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([17, 17,  1,  ..., 17, 17, 17]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0020,  ..., 0.0007, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([15, 15, 21,  ..., 15, 15, 15]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0020,  ..., 0.0007, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([31, 31, 17,  ..., 31, 31, 31]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0020,  ..., 0.0008, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([10, 10,  0,  ..., 10, 10, 10]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0021,  ..., 0.0007, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([28, 28, 22,  ..., 28, 28, 28]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0020,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([13, 13, 18,  ..., 13, 13, 13]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0021,  ..., 0.0007, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([15, 15,  0,  ..., 15, 15, 15]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0021,  ..., 0.0007, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([10, 10,  6,  ..., 10, 10, 10]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0022,  ..., 0.0007, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([23, 23, 10,  ..., 23, 23, 23]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0023,  ..., 0.0008, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([25, 25,  3,  ..., 25, 25, 25]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0023,  ..., 0.0008, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([11, 11,  6,  ..., 11, 11, 11]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0024,  ..., 0.0008, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([19, 19,  9,  ..., 19, 19, 19]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0023,  ..., 0.0008, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 2,  2, 13,  ...,  2,  2,  2]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0025,  ..., 0.0007, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([29, 29,  5,  ..., 29, 29, 29]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0024,  ..., 0.0008, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 6,  6, 26,  ...,  6,  6,  6]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0007, 0.0009, 0.0023,  ..., 0.0008, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 6,  6, 27,  ...,  6,  6,  6]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0025,  ..., 0.0007, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([28, 28, 11,  ..., 28, 28, 28]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0025,  ..., 0.0008, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([16, 16, 21,  ..., 16, 16, 16]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0024,  ..., 0.0008, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([19, 19, 13,  ..., 19, 19, 19]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0024,  ..., 0.0008, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 6,  6, 11,  ...,  6,  6,  6]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0024,  ..., 0.0008, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([29, 29,  1,  ..., 29, 29, 29]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0023,  ..., 0.0008, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 6,  6, 13,  ...,  6,  6,  6]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0024,  ..., 0.0007, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([12, 12, 29,  ..., 12, 12, 12]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0024,  ..., 0.0008, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 6,  6, 15,  ...,  6,  6,  6]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0023,  ..., 0.0008, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([19, 19, 27,  ...,  2, 19, 19]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0022,  ..., 0.0008, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([10,  1,  0,  ..., 10, 10, 10]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0024,  ..., 0.0008, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([26, 26, 28,  ..., 26, 26, 26]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0022,  ..., 0.0008, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([17, 17, 29,  ..., 17, 17, 17]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0023,  ..., 0.0008, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([16, 16,  8,  ..., 16, 16, 16]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0022,  ..., 0.0008, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([7, 7, 9,  ..., 7, 7, 7]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0022,  ..., 0.0008, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([29, 29, 18,  ..., 29, 29, 29]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0021,  ..., 0.0007, 0.0006, 0.0005],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([18, 18,  7,  ..., 18, 18, 18]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0022,  ..., 0.0007, 0.0006, 0.0005],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([16, 16,  2,  ..., 16, 16, 16]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0021,  ..., 0.0007, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 3,  3, 18,  ...,  3,  3,  3]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0005, 0.0009, 0.0021,  ..., 0.0007, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 6,  6, 25,  ...,  6,  6,  6]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0020,  ..., 0.0007, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([19, 19,  4,  ..., 19, 19, 19]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0020,  ..., 0.0007, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([11, 11,  3,  ..., 11, 11, 11]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0020,  ..., 0.0007, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([11, 11, 19,  ..., 11, 11, 11]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0005, 0.0008, 0.0020,  ..., 0.0007, 0.0005, 0.0005],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([25, 25, 30,  ..., 25, 25, 25]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0005, 0.0008, 0.0020,  ..., 0.0007, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([15, 15,  2,  ..., 15, 15, 15]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0019,  ..., 0.0007, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 7,  7, 27,  ...,  7,  7,  7]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0019,  ..., 0.0007, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 5,  5, 17,  ...,  5,  5,  5]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0019,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([12, 12, 28,  ..., 12, 12, 12]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0019,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 0,  0, 21,  ...,  0,  0,  0]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0018,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([17, 17, 27,  ..., 17, 17, 17]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0009, 0.0018,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([25, 25, 16,  ..., 25, 25, 25]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0018,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 5,  5, 12,  ...,  5,  5,  5]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0018,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([16, 16, 17,  ..., 16, 16, 16]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0018,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([27, 27,  7,  ..., 27, 27, 27]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0018,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([30, 30,  1,  ..., 30, 30, 30]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0018,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([24, 24, 22,  ..., 24, 24, 24]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0018,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([11, 11, 25,  ..., 11, 11, 11]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0005, 0.0008, 0.0018,  ..., 0.0007, 0.0006, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 3, 8,  ..., 3, 3, 3]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0018,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([19, 19, 10,  ..., 19, 19, 19]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0005, 0.0008, 0.0018,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 2,  2, 15,  ...,  2,  2,  2]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0018,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([30, 30, 25,  ..., 30, 30, 30]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0018,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([27, 27, 15,  ..., 27, 27, 27]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0018,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 6,  6, 31,  ...,  6,  6,  6]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0018,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([14, 14, 15,  ..., 14, 14, 14]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0005, 0.0007, 0.0018,  ..., 0.0006, 0.0006, 0.0005],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([18, 18, 29,  ..., 18, 18, 18]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0018,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([15, 15,  5,  ..., 15, 15, 15]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0004, 0.0007, 0.0018,  ..., 0.0006, 0.0006, 0.0005],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([14, 14, 12,  ..., 14, 14, 14]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0005, 0.0008, 0.0018,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([10, 10,  9,  ..., 10, 10, 10]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0018,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([30, 30, 20,  ..., 30, 30, 30]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0018,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([14, 14, 11,  ..., 14, 14, 14]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0018,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([31, 31, 14,  ..., 31, 31, 31]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0005, 0.0007, 0.0018,  ..., 0.0006, 0.0006, 0.0005],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 5,  ..., 0, 0, 0]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0005, 0.0008, 0.0018,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 1,  1, 19,  ...,  1,  1,  1]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0005, 0.0007, 0.0018,  ..., 0.0006, 0.0006, 0.0005],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([29, 29,  2,  ..., 29, 29, 29]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0018,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([29, 29,  2,  ..., 29, 29, 29]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0018,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([29, 29, 22,  ..., 29, 29, 29]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0018,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([23, 23, 19,  ..., 23, 23, 23]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0018,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 3,  3, 28,  ...,  3,  3,  3]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0019,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([13, 13, 22,  ..., 13, 13, 13]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0019,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 5,  5, 21,  ...,  5,  5,  5]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0005, 0.0007, 0.0019,  ..., 0.0006, 0.0006, 0.0005],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 3,  3, 28,  ...,  3,  3,  3]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0019,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([29, 29, 20,  ..., 29, 29, 29]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0020,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([19, 19, 29,  ..., 19, 19, 19]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0007, 0.0020,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([ 7,  7, 28,  ...,  7,  7,  7]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0006, 0.0008, 0.0020,  ..., 0.0007, 0.0007, 0.0006],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([5, 5, 4,  ..., 5, 5, 5]))\n",
      "torch.return_types.max(\n",
      "values=tensor([0.0003, 0.0005, 0.0020,  ..., 0.0004, 0.0005, 0.0003],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([4, 4, 3,  ..., 4, 4, 4]))\n",
      "Epoch: 1 \t Training Loss: 0.074819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [108]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-4\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m     10\u001b[0m n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [107]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, n_epochs)\u001b[0m\n\u001b[1;32m     36\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m Training Loss: \u001b[39m\u001b[38;5;132;01m{:.6f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, train_loss))\n\u001b[0;32m---> 40\u001b[0m p, r, f, roc_auc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m Validation p: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m, r:\u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m, f: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m, roc_auc: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, p, r, f, roc_auc))\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# get performance data\u001b[39;00m\n",
      "Input \u001b[0;32mIn [104]\u001b[0m, in \u001b[0;36meval\u001b[0;34m(model, val_loader)\u001b[0m\n\u001b[1;32m     35\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((y_true, y\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     37\u001b[0m p, r, f, _ \u001b[38;5;241m=\u001b[39m precision_recall_fscore_support(y_true, y_pred)\n\u001b[0;32m---> 39\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m p, r, f, roc_auc\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:575\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    568\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[1;32m    569\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    572\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    573\u001b[0m     )\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sklearn/metrics/_base.py:118\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    116\u001b[0m     y_true_c \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mtake([c], axis\u001b[38;5;241m=\u001b[39mnot_average_axis)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m    117\u001b[0m     y_score_c \u001b[38;5;241m=\u001b[39m y_score\u001b[38;5;241m.\u001b[39mtake([c], axis\u001b[38;5;241m=\u001b[39mnot_average_axis)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m--> 118\u001b[0m     score[c] \u001b[38;5;241m=\u001b[39m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscore_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Average the results\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:337\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03m\"\"\"Binary roc auc score.\"\"\"\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_true)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    338\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not defined in that case.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    340\u001b[0m     )\n\u001b[1;32m    342\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = INPREM(len(types), max_num_visits)\n",
    "\n",
    "# load the loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# load the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "\n",
    "n_epochs = 5\n",
    "train(model, train_loader, val_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3b9314-e48e-41f1-bfec-a23381f59b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bbc121b-8d7d-4d90-84b8-eed2a485ace3",
   "metadata": {},
   "source": [
    "## Abblations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c088435-9f4e-47e4-9fd2-3743022347db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa0f9c2-bc37-46de-bc94-36feba5fea66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7aa2f7-8c59-4eb2-b373-05eb7da9729b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

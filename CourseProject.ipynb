{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed3a4738-2e3b-4230-a760-5aa18887dbdd",
   "metadata": {},
   "source": [
    "# Deep Learning For Healthcare Course Project: INPREM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161bee9d-8169-434e-826e-2e4c9b29c687",
   "metadata": {},
   "source": [
    "https://www.kdd.org/kdd2020/accepted-papers/view/inprem-an-interpretable-and-trustworthy-predictive-model-for-healthcare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db47c1bd-157c-444a-be21-ebc3cdbd4645",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5063b31c-2e09-4c90-933d-34354f6fb5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: sparsemax in /opt/conda/lib/python3.8/site-packages (0.1.9)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from sparsemax) (1.11.0a0+bfe5ad2)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch->sparsemax) (4.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U sparsemax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f3dc9044-b4f4-4504-99a1-041a4d89e6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psutil\n",
    "import pickle\n",
    "import json\n",
    "import ast\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from icd9 import ICD9\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sparsemax import Sparsemax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0dc863de-4dea-4fe9-b07c-f02da06a2872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU\n",
      "using demo data\n"
     ]
    }
   ],
   "source": [
    "# set seed\n",
    "seed = 24\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "# validate GPU usage\n",
    "print(\"using GPU\") if torch.cuda.is_available() else print(\"no GPU found\")\n",
    "\n",
    "# define data path\n",
    "use_demo = True\n",
    "if use_demo:\n",
    "    DATA_PATH = \"demodata/\" # work with open source data\n",
    "    print(\"using demo data\")\n",
    "else:\n",
    "    DATA_PATH = \"data/\" # work with certified patient data\n",
    "    print(\"using patient data\")\n",
    "\n",
    "tree = ICD9('codes.json')\n",
    "# tree.find('001.1').parent.parent.code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9b317c7b-cdec-477b-ab90-f5004336588c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADMISSIONS.csv\t   D_ICD_DIAGNOSES.csv\trtypes.pkl  types.pkl\r\n",
      "DIAGNOSES_ICD.csv  ICUSTAYS.csv\t\trtypes.txt  types.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls {DATA_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59820ba-ebce-486b-8c10-013ffb6615cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faafcd45-05f9-4855-89dc-c9f3afe2a3c9",
   "metadata": {},
   "source": [
    "For example, SUBJECT_ID refers to a unique patient, HADM_ID refers to a unique admission to the hospital, and ICUSTAY_ID refers to a unique admission to an intensive care unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "78d39bac-2632-4d00-9982-d3d5c915774d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diag_icd (1761 lines):\n",
      "    hadm_id icd9_code\n",
      "0   142345     99591\n",
      "1   142345     99662\n",
      "2   142345      5672\n",
      "3   142345     40391\n",
      "4   142345     42731\n",
      "\n",
      "icustays (136 lines):\n",
      "    subject_id  hadm_id  icustay_id              outtime\n",
      "0       10006   142345      206504  2164-10-25 12:21:07\n",
      "1       10011   105331      232110  2126-08-28 18:59:00\n",
      "2       10013   165520      264446  2125-10-07 15:13:52\n",
      "3       10017   199207      204881  2149-05-31 22:19:17\n",
      "4       10019   177759      228977  2163-05-16 03:47:04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(filepath):\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "def convert_datetime_to_day(df):\n",
    "    temp = pd.DataFrame()\n",
    "    temp[\"date\"] = pd.to_datetime(df['outtime'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    return str(temp['date'].dt.year) + str(temp['date'].dt.month) + str(temp['date'].dt.day)\n",
    "\n",
    "diag_icd = load_dataset(os.path.join(DATA_PATH, 'DIAGNOSES_ICD.csv'))\n",
    "icd_descriptions = load_dataset(os.path.join(DATA_PATH, 'D_ICD_DIAGNOSES.csv'))\n",
    "icustays = load_dataset(os.path.join(DATA_PATH, 'ICUSTAYS.csv'))\n",
    "admissions = load_dataset(os.path.join(DATA_PATH, 'ADMISSIONS.csv'))\n",
    "\n",
    "diag_icd = diag_icd.rename(columns={\"hadm_id\".upper(): \"hadm_id\", \"icd9_code\".upper(): \"icd9_code\"})\n",
    "icustays = icustays.rename(columns={\"subject_id\".upper(): \"subject_id\", \"hadm_id\".upper(): \"hadm_id\", \"icustay_id\".upper(): \"icustay_id\", \"outtime\".upper(): \"outtime\"})\n",
    "\n",
    "diag_icd = diag_icd[[\"hadm_id\", \"icd9_code\"]]\n",
    "icustays = icustays[[\"subject_id\", \"hadm_id\", \"icustay_id\", \"outtime\"]]\n",
    "\n",
    "\n",
    "print(f\"diag_icd ({len(diag_icd)} lines):\\n\", diag_icd.head(), end=\"\\n\\n\")\n",
    "print(f\"icustays ({len(icustays)} lines):\\n\", icustays.head(), end=\"\\n\\n\")\n",
    "# print(f\"admissions ({admissions.size} lines):\\n\", admissions.head(), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b12ade38-be99-44c0-9fb7-e5c2dc2b1a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joined_df (1897 lines):\n",
      "   icd9_code  subject_id  icustay_id              outtime\n",
      "0     99591       10006      206504  2164-10-25 12:21:07\n",
      "1     99662       10006      206504  2164-10-25 12:21:07\n",
      "2      5672       10006      206504  2164-10-25 12:21:07\n",
      "3     40391       10006      206504  2164-10-25 12:21:07\n",
      "4     42731       10006      206504  2164-10-25 12:21:07\n"
     ]
    }
   ],
   "source": [
    "joined_df = pd.merge(diag_icd, icustays, how='inner', on='hadm_id')[[\"icd9_code\", \"subject_id\", \"icustay_id\", \"outtime\"]]\n",
    "print(f\"joined_df ({len(joined_df)} lines):\\n\", joined_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1f3438-5929-4f94-90fd-50e2af5b69b3",
   "metadata": {},
   "source": [
    "Convert y in to category labels. If (3, 4 ,5) always use left 3. If it starts with E, use (Exxx). If it starts with V, use (Vxx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6c847451-714f-4bd3-b80a-a37a497105c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 19 patients\n"
     ]
    }
   ],
   "source": [
    "def convert_codes(codes):\n",
    "    out = []\n",
    "    for code in codes:\n",
    "        code = str(code)\n",
    "        if code[0] == \"E\":\n",
    "            c = code[:4]\n",
    "        else:\n",
    "            c = code[:3]\n",
    "        out.append(c)\n",
    "        \n",
    "        unique_codes.add(c)\n",
    "       \n",
    "    return out\n",
    "\n",
    "\n",
    "def build_dictionaries(codes): # use our codes (kept getting keyError)\n",
    "    \"\"\"Construct dicts to map/ reverse map string input codes to keys, e.g. {'001': 0, '002': 1}\n",
    "    \"\"\"\n",
    "    types = dict((diag, idx) for idx, diag in enumerate(codes))\n",
    "    rtypes = dict((idx, diag) for idx, diag in enumerate(codes))\n",
    "    \n",
    "    return types, rtypes\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "all_codes = []\n",
    "unique_codes = set()\n",
    "\n",
    "for name, patient in joined_df.sort_values(\"outtime\").groupby([\"subject_id\"]):\n",
    "    visits = []\n",
    "    for _, visit in patient.groupby([\"icustay_id\"]):\n",
    "        codes = visit[\"icd9_code\"].tolist()\n",
    "        codes = convert_codes(codes)\n",
    "        visits.append(codes)\n",
    "    if len(visits) >= 2:\n",
    "        x, y_ = visits[:-1], visits[-1]\n",
    "        X.append(x)\n",
    "        y.append(y_)\n",
    "\n",
    "types, rtypes = build_dictionaries(list(unique_codes))\n",
    "print(f\"Using {len(X)} patients\")\n",
    "\n",
    "# check mapping\n",
    "# print(unique_codes)\n",
    "# print('diag mapping for DIAG_V10:', types['V10']) # 75\n",
    "# print('reverse mapping for index 75:', rtypes[75])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "79702804-810c-41c6-9381-fb1681ac3cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(X) == len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "69f80811-2ae9-44bf-81bc-77b08f9edabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275 codes\n",
      "275 types mappings\n"
     ]
    }
   ],
   "source": [
    "# print(\"visits (x):\", X, \"\\n\")\n",
    "# print(\"last visit (y):\", y)\n",
    "\n",
    "print(len(unique_codes), \"codes\") \n",
    "print(len(types), \"types mappings\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0f406311-1f41-41f0-86dc-2d09a286533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICD 9 Codes for Binary Classification\n",
    "diabetes = (\"Diabetes\", \"250.xx\")\n",
    "heart_failure = (\"Heary Failure\", \"428.xx\")\n",
    "chronic_kidney_disease = (\"Chronic Kidney Disease\", \"585.xx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8da5af8",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b7071d",
   "metadata": {},
   "source": [
    "For each task, we randomly split each dataset into training, validation, and testing sets five times in a 75:10:15 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1d8b0e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_size = 0.75\n",
    "\n",
    "X_train, X_remain, y_train, y_remain = train_test_split(X, y, train_size=0.75)\n",
    "\n",
    "test_size = 0.6 # (valid is 10% of remaining 25%, test is 15% of remaining 25%)\n",
    "\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_remain, y_remain, test_size=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bf4afc-5be4-4ac2-831a-60d6eaa52c10",
   "metadata": {},
   "source": [
    "## Build Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3895e91d-962b-40de-852d-afb900d64b6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return (self.x[index], self.y[index])\n",
    "        \n",
    "        \n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "val_dataset = CustomDataset(X_valid, y_valid)\n",
    "test_dataset = CustomDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7f5e7e-a159-45df-a748-97b3c904c3fc",
   "metadata": {},
   "source": [
    "## Load the Data (DataLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f46fda0-2d1c-4529-a191-8f3f190e1b57",
   "metadata": {},
   "source": [
    "For each task, we randomly split each dataset into training, validation, and testing sets five times in a 75:10:15 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "784b31cb-ac66-46e2-80dd-b0d9813a973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_retain(data):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        data: a list of samples fetched from `CustomDataset`\n",
    "        \n",
    "    Outputs:\n",
    "        x: a tensor of shape (# patients, max # visits, max # diagnosis codes) of type torch.long\n",
    "        masks: a tensor of shape (# patients, max # visits, max # diagnosis codes) of type torch.bool\n",
    "        rev_x: same as x but in reversed time. This will be used in our RNN model for masking \n",
    "        rev_masks: same as mask but in reversed time. This will be used in our RNN model for masking\n",
    "        y: a tensor of shape (# patients) of type torch.float\n",
    "        \n",
    "    Note that you can obtains the list of diagnosis codes and the list of hf labels\n",
    "        using: `sequences, labels = zip(*data)`\n",
    "    \"\"\"\n",
    "\n",
    "    sequences, labels = zip(*data)\n",
    "    num_patients = len(sequences)\n",
    "    num_visits = [len(patient) for patient in sequences]\n",
    "    num_codes = [len(visit) for patient in sequences for visit in patient]\n",
    "\n",
    "    max_num_visits = max(num_visits)\n",
    "    max_num_codes = max(num_codes)\n",
    "    \n",
    "    y = torch.zeros((len(labels), len(types)), dtype=torch.bool)\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        # create one-hot vector\n",
    "        for l in label:\n",
    "            plc = types[l]\n",
    "            y[i][plc] = True\n",
    "    \n",
    "    x = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.long)\n",
    "    rev_x = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.long)\n",
    "    masks = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.bool)\n",
    "    rev_masks = torch.zeros((num_patients, max_num_visits, max_num_codes), dtype=torch.bool)\n",
    "    for i_patient, patient in enumerate(sequences):\n",
    "        count = 0\n",
    "        for j_visit, visit in enumerate(patient):\n",
    "            \"\"\"\n",
    "            TODO: update `x`, `rev_x`, `masks`, and `rev_masks`\n",
    "            \"\"\"\n",
    "            visit_len = len(visit)\n",
    "            \n",
    "            typed_visit = visit.copy()\n",
    "            for idx, code in enumerate(visit): # convert to mapping\n",
    "                typed_visit[idx] = types[visit[idx]]\n",
    "            \n",
    "            x[i_patient][j_visit][:visit_len] = torch.tensor(typed_visit, dtype=torch.long)\n",
    "            masks[i_patient][j_visit][:visit_len] = torch.ones((visit_len),dtype=torch.bool)\n",
    "            count += 1\n",
    "            \n",
    "        reverse_x = x[i_patient][:count]\n",
    "        reverse_mask = masks[i_patient][:count]\n",
    "        \n",
    "        rev_x[i_patient][:count] = torch.flip(reverse_x, [0])\n",
    "        rev_masks[i_patient][:count] = torch.flip(reverse_mask, [0])\n",
    "        \n",
    "    return x, masks, rev_x, rev_masks, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c81276f8-6ccc-4e9b-bc7d-bc16d43dbe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_inprem(data):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        data: a list of samples fetched from `CustomDataset`\n",
    "        \n",
    "    Outputs:\n",
    "        x: a tensor of shape (# patients, max # visits, max # diagnosis codes) of type torch.long\n",
    "    Note that you can obtains the list of diagnosis codes and the list of hf labels\n",
    "        using: `sequences, labels = zip(*data)`\n",
    "    \"\"\"\n",
    "\n",
    "    sequences, labels = zip(*data)\n",
    "    num_patients = len(sequences)\n",
    "    num_visits = [len(patient) for patient in sequences]\n",
    "    num_codes = [len(visit) for patient in sequences for visit in patient]\n",
    "\n",
    "    max_num_visits = max(num_visits)\n",
    "    max_num_codes = max(num_codes)\n",
    "    num_types = len(types)\n",
    "    \n",
    "    y = torch.zeros((len(labels), num_types), dtype=torch.bool)\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        # create one-hot vector\n",
    "        for l in label:\n",
    "            plc = types[l]\n",
    "            y[i][plc] = True\n",
    "    \n",
    "    x = torch.zeros((num_patients, max_num_visits, num_types), dtype=torch.long)\n",
    "    o = torch.zeros((num_patients, max_num_visits), dtype=torch.long)\n",
    "    masks = torch.zeros((num_patients, max_num_visits, num_types), dtype=torch.bool)\n",
    "    for i_patient, patient in enumerate(sequences):\n",
    "        count = 1\n",
    "        for j_visit, visit in enumerate(patient):\n",
    "            for code in visit : # convert to mapping\n",
    "                plc = types[code]\n",
    "                x[i_patient][j_visit][plc] = True\n",
    "            o[i_patient][j_visit] = count\n",
    "            count += 1\n",
    "        \n",
    "    return x, o, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c2d03a1e-7bd8-467c-b155-b1ab699ce8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def load_data(train_dataset, val_dataset, test_dataset, collate_fn):\n",
    "    \n",
    "    batch_size = 32\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn_inprem, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn_inprem)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn_inprem)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "train_loader, val_loader, test_loader = load_data(train_dataset, val_dataset, test_dataset, collate_fn_inprem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c7b45-5f82-4852-8ad2-a7775c775d75",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ee0171-82a3-4f49-8baa-fef7e1f5efee",
   "metadata": {},
   "source": [
    "We treat the medical events taking place in EHR as medical codes, which are denoted as $c_{1}, c_{2},... c_{|C|}$ ‚àà ùê∂, where |ùê∂| is the total number of unique medical codes.\n",
    "\n",
    "One specific patient consist of a sequence of visits $v_{1}, v_{2},... v_{T}$ where we denote the number of visits in total as T.\n",
    "\n",
    "Each visit contains a subset of medical codes, and we denote each visit as a binary vector  $v_{t} ‚àà \\{0, 1\\}_{|C|}$, where the ùëñ-th element is set to 1 if the ùë°-th visit contains the medical code $c_{i}$, otherwise 0. The visits  $v_{1}, v_{2},... v_{T}$ are stacked to form an input matrix $X ‚àà \\{0, 1\\}^{|C|xT}$ , which we use as the input for the network\n",
    "\n",
    "$E_{v} = {W}_{v}X$\n",
    "\n",
    "$E_{o} = {W}_{o}O$\n",
    "\n",
    "$E_{r} = \\alpha(\\beta \\odot (E_{v}+E_{o}))^{T}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "17b78ac0-1bc5-46fa-98ac-83ca4cd3695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaAttention(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lin = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        self.sparsemax = Sparsemax(dim=-1)\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, g):\n",
    "        \n",
    "        y = self.lin(g)\n",
    "        sparse_max = self.sparsemax(y)\n",
    "        soft_max = self.softmax(y)\n",
    "        \n",
    "        out = (sparse_max + soft_max) / 2\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class BetaAttention(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lin = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, h):\n",
    "        \n",
    "        y = self.lin(h)\n",
    "        out = torch.tanh(y)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c92abe",
   "metadata": {},
   "source": [
    "## Retain (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "eae07459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RETAIN(\n",
       "  (embedding_v): Embedding(275, 256)\n",
       "  (embedding_o): Embedding(275, 256)\n",
       "  (rnn_a): GRU(256, 256, batch_first=True)\n",
       "  (rnn_b): GRU(256, 256, batch_first=True)\n",
       "  (att_a): AlphaAttention(\n",
       "    (lin): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (sparsemax): Sparsemax(dim=-1)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  )\n",
       "  (att_b): BetaAttention(\n",
       "    (lin): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (do): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RETAIN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_codes, embedding_dim=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_v = nn.Embedding(num_codes, embedding_dim)\n",
    "        self.embedding_o = nn.Embedding(num_codes, embedding_dim)\n",
    "        \n",
    "        self.rnn_a = nn.GRU(embedding_dim, embedding_dim, batch_first=True)\n",
    "        self.rnn_b = nn.GRU(embedding_dim, embedding_dim, batch_first=True)\n",
    "        \n",
    "        self.att_a = AlphaAttention(embedding_dim)\n",
    "        self.att_b = BetaAttention(embedding_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(embedding_dim, 1)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.do = nn.Dropout(.5)\n",
    "    \n",
    "    def forward(self, X, masks, rev_X, rev_masks):\n",
    "    \n",
    "        rev_X = self.embedding_v(rev_X)\n",
    "        rev_X = self.embedding_o(rev_X)\n",
    "        \n",
    "        X_v = self.embedding_v(X)\n",
    "        X_o = self.embedding_o(X)\n",
    "        \n",
    "        g, _ = self.rnn_a(rev_x)\n",
    "        h, _ = self.rnn_b(rev_x)\n",
    "        \n",
    "        alpha = self.att_a(g)\n",
    "        beta = self.att_b(h)\n",
    "        \n",
    "        # c = attention_sum(alpha, beta, rev_x, rev_masks) # RETAIN\n",
    "        \n",
    "        # er = alpha * (beta @ (X_v + X_o)).T # INPREM\n",
    "        \n",
    "        logits = self.fc(c)\n",
    "        probs = self.sigmoid(logits)\n",
    "                      \n",
    "        out = F.softmax(probs.squeeze())\n",
    "    \n",
    "\n",
    "# load the model here\n",
    "retain = RETAIN(num_codes = len(types))\n",
    "retain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ce4102",
   "metadata": {},
   "source": [
    "## INPREM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "74799646-67a2-4780-a4e2-8eabedce15f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INPREM(\n",
       "  (embedding_v): Embedding(275, 256)\n",
       "  (embedding_o): Embedding(275, 256)\n",
       "  (att_a): AlphaAttention(\n",
       "    (lin): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (sparsemax): Sparsemax(dim=-1)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  )\n",
       "  (att_b): BetaAttention(\n",
       "    (lin): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (do): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class INPREM(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_codes, embedding_dim=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_v = nn.Embedding(num_codes, embedding_dim)\n",
    "        self.embedding_o = nn.Embedding(num_codes, embedding_dim)\n",
    "        \n",
    "        self.att_a = AlphaAttention(embedding_dim)\n",
    "        self.att_b = BetaAttention(embedding_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(embedding_dim, 1)\n",
    "        \n",
    "        self.do = nn.Dropout(.5)\n",
    "    \n",
    "    def forward(self, X, O):\n",
    "        X_v = self.embedding_v(X)\n",
    "        X_o = self.embedding_o(O)\n",
    "        \n",
    "        X_o = X_o.unsqueeze(dim=2)\n",
    "        \n",
    "        print(X_v.shape)\n",
    "        print(X_o.shape)\n",
    "        \n",
    "        X = torch.concat((X_v, X_o), dim=2)\n",
    "        \n",
    "        beta = self.att_b(X)\n",
    "        alpha = self.att_a(beta)\n",
    "        \n",
    "        # er = alpha * (beta @ (X_v + X_o)).T # INPREM\n",
    "        \n",
    "        logits = self.fc(alpha)\n",
    "                      \n",
    "        out = F.softmax(logits.squeeze())\n",
    "    \n",
    "    \n",
    "# load the model here\n",
    "model = INPREM(num_codes = len(types))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe5e895-e644-4790-9a3e-51d2ffdfc451",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1ee84c93-6357-4d93-b612-b7fde9d30c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dataloader, device=None):\n",
    "    model.eval()\n",
    "    y_pred = torch.LongTensor()\n",
    "    y_score = torch.Tensor()\n",
    "    y_true = torch.LongTensor()\n",
    "    \n",
    "    for DATA in dataloader:\n",
    "        y_logit = model(DATA)\n",
    "\n",
    "        y_hat = (y_logit > 0.5).int()\n",
    "\n",
    "        y_score = torch.cat((y_score,  y_logit.detach().to('cpu')), dim=0)\n",
    "        y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n",
    "        y_true = torch.cat((y_true, y.detach().to('cpu')), dim=0)\n",
    "    \n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    roc_auc = roc_auc_score(y_true, y_score)\n",
    "    \n",
    "    return p, r, f, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e5aa54-d7b3-4983-a834-77c898657366",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e402cdc6-bb7b-4f0b-8efd-f6efff628b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, n_epochs):\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        train_loss = 0\n",
    "        for x, o, y in train_loader:\n",
    "        # for DATA, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x, o)\n",
    "\n",
    "            loss = criterion(y_hat, y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "        \n",
    "        p, r, f, roc_auc = eval(model, val_loader)\n",
    "        \n",
    "        print('Epoch: {} \\t Validation p: {:.2f}, r:{:.2f}, f: {:.2f}, roc_auc: {:.2f}'.format(epoch+1, p, r, f, roc_auc))\n",
    "        \n",
    "        # get performance data\n",
    "        print('The CPU usage over the last 5 seconds is: {}'.format(psutil.cpu_percent(5)))\n",
    "        print('RAM memory % used is: {} of {}'.format(psutil.virtual_memory()[2], psutil.virtual_memory()[0]))\n",
    "        print('GPU statistics: {}'.format(torch.cuda.mem_get_info()))\n",
    "        \n",
    "    return round(roc_auc, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630845b1-f35a-4f28-93d3-593bfa3e9993",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35875830-7833-4907-9b0e-721957ac0db9",
   "metadata": {},
   "source": [
    "For training all approaches, we use Adam with the batch size of 32 and the learning rate of 0.0005. The weight decay is set to ùúÜ = 0.0001 and the dropout rate is set to 0.5 for all approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3ffaa109-7d45-4a3e-b9bb-0c9748a12770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 14, 275, 256])\n",
      "torch.Size([14, 14, 1, 256])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (54096x1 and 256x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_432/698199609.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_432/3095809285.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, n_epochs)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# for DATA, y in train_loader:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_432/671251133.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, O)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# er = alpha * (beta @ (X_v + X_o)).T # INPREM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1952\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1954\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (54096x1 and 256x1)"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "# model = IMPREM(num_codes = len(types))\n",
    "\n",
    "# load the loss function\n",
    "criterion = nn.BCELoss()\n",
    "# load the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "\n",
    "n_epochs = 5\n",
    "train(model, train_loader, val_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3b9314-e48e-41f1-bfec-a23381f59b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bbc121b-8d7d-4d90-84b8-eed2a485ace3",
   "metadata": {},
   "source": [
    "## Abblations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c088435-9f4e-47e4-9fd2-3743022347db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
